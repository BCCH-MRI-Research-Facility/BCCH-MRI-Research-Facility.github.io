[
  {
    "objectID": "mrisoftware/3D-Slicer.html#loading-nifti-files",
    "href": "mrisoftware/3D-Slicer.html#loading-nifti-files",
    "title": "3D Slicer",
    "section": "Loading Nifti Files",
    "text": "Loading Nifti Files\nMany medical imaging files come in what‚Äôs called the ‚ÄòNIfTI‚Äô format (stands for Neuroimaging Informatics Technology Initiative). These files will end in either .nii or a compressed version .nii.gz\nTo load a .nii or .nii.gz file:\nFile &gt; Add Data &gt; Choose File(s) to Add\n\nNow you should be able to view three different ‚Äòslices‚Äô of your brain: \nUsing your mouse, hover over the view you want to interact with, and use your scroll wheel to navigate through slices. Or hold down CTRL while using the scroll wheel to zoom in.\nTo move the image around (in case you want to zoom into a particular area), hold down your scroll-wheel and move your cursor.",
    "crumbs": [
      "Home",
      "MRI Software",
      "3D Slicer"
    ]
  },
  {
    "objectID": "mrisoftware/3D-Slicer.html#d-rendering",
    "href": "mrisoftware/3D-Slicer.html#d-rendering",
    "title": "3D Slicer",
    "section": "3D Rendering",
    "text": "3D Rendering\nWould you like to see your brain in 3D and perform a ‚Äòvirtual dissection‚Äô?\n\nClick on the \"Welcome to Slicer\" drop down menu (Top left)\nClick on \"Volume Rendering\"\nClick on the 'closed eye' in the top left (beside the name of the image)\nYou can then do a digital dissection by clicking on Crop: Enable; Display ROI, then click on the green, red, blue whatever circles to move the planes to dissect\n\nHere is a gif that shows these steps in detail [Note: if the image is too small, right-click, and press ‚ÄòOpen Image in New Tab‚Äô]\n\nMore info: slicer.readthedocs.io/en/latest/user_guide/modules/volumerendering.html",
    "crumbs": [
      "Home",
      "MRI Software",
      "3D Slicer"
    ]
  },
  {
    "objectID": "mrisoftware/3D-Slicer.html#manual",
    "href": "mrisoftware/3D-Slicer.html#manual",
    "title": "3D Slicer",
    "section": "Manual",
    "text": "Manual\nslicer.readthedocs.io/en/latest/",
    "crumbs": [
      "Home",
      "MRI Software",
      "3D Slicer"
    ]
  },
  {
    "objectID": "mrisoftware/3D-Slicer.html#faq",
    "href": "mrisoftware/3D-Slicer.html#faq",
    "title": "3D Slicer",
    "section": "FAQ",
    "text": "FAQ\nslicer.org/wiki/Documentation/4.5/FAQ/General",
    "crumbs": [
      "Home",
      "MRI Software",
      "3D Slicer"
    ]
  },
  {
    "objectID": "orientation/mrisafetyfaq.html",
    "href": "orientation/mrisafetyfaq.html",
    "title": "MRI Safety FAQ",
    "section": "",
    "text": "Frequencly Asked Questions Answered\n[Note: the following was taken from here.\nThis is a rough guide; some things may no longer be accurate for our facility]\n\nCan you have an MRI if you have fillings, retainers or braces on your teeth?\n\nThe metal in most fillings is not affected by the MRI system‚Äôs magnetic field. However, the fillings may cause some distortion of the images if you are having a scan of the brain or facial area.\n\nCan I have an MRI exam if I have a permanent retainer or braces on my teeth?\n\nThe recommendation is not to scan a subject with retainers or braces because of distortion can occur that can affect the quality of the data.\n\nCan you have make-up on for an MRI?\n\nSome cosmetics contain metals that can interact with MRI magnets, so on the day of the MRI, if possible, ask your subject to not wear makeup. Also, minimize hairspray and forgo antiperspirants and sunscreens, which contain metals, that could interfere with the scan and reduce the quality of the images.\n\nCan you put on deodorant for an MRI?\n\nPlease refrain from wearing any powder, perfumes, deodorant and/or lotions on your underarms and breasts prior to the procedure. Since the MRI is a magnet, please let us know if you have any metal in or on your body.\n\nIs titanium safe for MRI?\n\nTitanium implants are MRI compatible. Subjects with nontitanium implants should inform the MRI safety officer 7 days prior to the procedure to check with the manufacture for condition that allow safely conducting an MRI scan.\n\nWhat do you wear for an MRI?\n\nIf the subject‚Äôs clothes have any metal fasteners or metallic design in close proximity to the anatomy being scanned, you should ask the subject to change into a hospital gown. If the clothing is made of a stretchy material, the subject must change into a hospital gown as a precautionary measure of safety to prevent possible burns to the skin. A locker will be supplied to secure their belongings.\n\nIs it safe to have an MRI while pregnant?\n\nUnless the research MRI study involves prenatal or pregnant subjects, pregnant subjects are excluded.\n\nAre piercings safe for MRI?\n\nIt is the policy to remove all piercings before you scan your subject to avoid any possible burns due to heating of the metal used in the piercings. Piercings, if not removed, i.e.¬†earrings, will cause distortion to the image.\n\n\nSafety of frequently asked implant MRI compatibility:\nIf a subject has an implant it must be reviewed by the MRI safety officer before the subject can be scanned. Written documentation must be provided to determine the type of implant.\n\nHearing Aids and Other Hearing Systems\nUnsafe.\n\n\nHeart Valves and Annuloplasty Rings\nSafe to scan at 3T or less.\n\n\nHemostatic clips, other clips, fasteners, staples\nSafe at 3T or less.\n\n\nIUDs and other contraceptive devices\n\nCopper T and Copper 7: Safe at 1.5 T or less.\nCopper T 380A: Safe at 3T or less.\nStainless steel IUDs: Unsafe.\nMirena IUD: Safe.\nImplanon implant: Safe.\nEssure: Safe to scan at 3T or less.\n\n\n\nMagnetically activated implants and devices\nUnsafe.\n\n\nNeurostimulation system\nUnsafe.\n\n\nOtologic Implants\nUnsafe.\n\n\nPenile Implants\nUnsafe ‚Äì Duraphase or Omniphase.\n\n\nPessary/Pessaries\nUnsafe ‚Äì metallic. Safe ‚Äì nonmetallic.\n\n\nOrthopedic implants\nMust check manufactures conditions for MRI safety.\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Home",
      "Orientation",
      "MRI Safety FAQ"
    ]
  },
  {
    "objectID": "orientation/index.html",
    "href": "orientation/index.html",
    "title": "Orientation",
    "section": "",
    "text": "MRI Safety FAQ\n\n\n\n\n\n\nsafety\n\n\nmri\n\n\n\nYour frequently asked MRI safety questions answered\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMattermost: Instant Messaging / Stay in Touch\n\n\n\n\n\n\ncollaboration\n\n\nsoftware\n\n\ninstant messaging\n\n\n\nInstant messaging app for users of the research MRI facility\n\n\n\n\n\n\n\n\n\nNo matching items\n\n Back to top",
    "crumbs": [
      "Home",
      "Orientation"
    ]
  },
  {
    "objectID": "mrimethods/eeg-fmri/ballistocardiogram-removal.html",
    "href": "mrimethods/eeg-fmri/ballistocardiogram-removal.html",
    "title": "EEG-fMRI Ballistocardiogram Cleaning (Rodriguez method)",
    "section": "",
    "text": "Reversed engineered code from Rodriguez (2016) for removal of the ballistocardiogram artifacts from EEG-fMRI data when the ECG fails to give a good signal. Cameron‚Äôs dissertation is included in this repository for transparency‚Äôs sake. This code requires Matlab and the Signal Processing Toolbox.\nIf you use this code, please cite:\nRodriguez, Cameron. (2016). Improvements to Simultaneous Electroencepalography-Functional Magnetic Resonance Imaging and Electroencepalographic Source Localization. PhD Thesis for the University of California, Los Angeles.",
    "crumbs": [
      "Home",
      "MRI Methods",
      "EEG-fMRI",
      "EEG-fMRI Ballistocardiogram Cleaning (Rodriguez method)"
    ]
  },
  {
    "objectID": "mrimethods/eeg-fmri/ballistocardiogram-removal.html#please-cite-rodriguez-2016",
    "href": "mrimethods/eeg-fmri/ballistocardiogram-removal.html#please-cite-rodriguez-2016",
    "title": "EEG-fMRI Ballistocardiogram Cleaning (Rodriguez method)",
    "section": "",
    "text": "Reversed engineered code from Rodriguez (2016) for removal of the ballistocardiogram artifacts from EEG-fMRI data when the ECG fails to give a good signal. Cameron‚Äôs dissertation is included in this repository for transparency‚Äôs sake. This code requires Matlab and the Signal Processing Toolbox.\nIf you use this code, please cite:\nRodriguez, Cameron. (2016). Improvements to Simultaneous Electroencepalography-Functional Magnetic Resonance Imaging and Electroencepalographic Source Localization. PhD Thesis for the University of California, Los Angeles.",
    "crumbs": [
      "Home",
      "MRI Methods",
      "EEG-fMRI",
      "EEG-fMRI Ballistocardiogram Cleaning (Rodriguez method)"
    ]
  },
  {
    "objectID": "mrimethods/eeg-fmri/ballistocardiogram-removal.html#removing-the-ballistocardiogram-with-no-ecg",
    "href": "mrimethods/eeg-fmri/ballistocardiogram-removal.html#removing-the-ballistocardiogram-with-no-ecg",
    "title": "EEG-fMRI Ballistocardiogram Cleaning (Rodriguez method)",
    "section": "Removing the Ballistocardiogram with no ECG",
    "text": "Removing the Ballistocardiogram with no ECG\n\nRemove the MR gradient signal from the EEG using your favourite software (here we used FIMRIB‚Äôs EEG tools [Niazy et al., 2005] in EEGLAB [Delorme & Makeig, 2004] saved as a .set file).\nSet up the paths to your data and change directories into the srcdir directory. Change the path to suit your dataset.\n\nsrcdir = fullfile('/Volumes', 'Lynne_32G', 'EEG', 'src');\ncd(scrdir)\n\nLoad the EEG run. Change to suit your dataset.\n\nEEG = load('-mat', [srcdir 'BHBMEG007_20210511_040344_GR.set']);\n\nGet the sampling rate. In the .set file, it is named srate and is an embedded structure of EEG. This may differ depending on the software used to remove the MR gradient noise.\n\nFs = EEG.srate\n\nRemove remaining gradient artifact at beginning and cut off part when net was removed at the end by cropping the signal.\nRestrict signal to channels included in Rodriguez 2016 for ballistocardiogram estimation (FT9 [EGI 67], TP9 [EGI 94], T7 [EGI 69], P7 [EGI 96], FT10 [EGI 219], TP10 [EGI 190], T8 [EGI 202], P8 [EGI 179]).\n\nchannels2keep = [67 94 69 96 219 190 202 179];\nstart = round(EEG.event(2).latency); % skip first TR as there is often gradient noise still in the signal  \ndata = double(EEG.data(channels2keep, start:end) );\n\nsubplot(8,1,1), plot(data(1,1:1500))\nsubplot(8,1,2), plot(data(2,1:1500))\nsubplot(8,1,3), plot(data(3,1:1500))\nsubplot(8,1,4), plot(data(4,1:1500))\nsubplot(8,1,5), plot(data(5,1:1500))\nsubplot(8,1,6), plot(data(6,1:1500))\nsubplot(8,1,7), plot(data(7,1:1500))\nsubplot(8,1,8), plot(data(8,1:1500))\n\n\n\nChannels to derive cardiac signal from.\n\n\n\nSubtract mean from each channel.\n\ndata = data - mean(data,2)\n\nCreate mean left and right channels\n\nLmean = mean(data(1:4,:));\nRmean = mean(data(5:8,:));\n\nRereference channels\n\nTake the difference of Lmean and Rmean\n\n\nLR = Lmean - Rmean;\nplot(LR(35000:40000))\n\n\n\nRereferenced channels.\n\n\n\nClean up output Step 10.1: LR mean Signal Conditioning/Filtering\n\n\nFilter series 1: Low Bandwidth\n\n0.75 Hz 6th order Butterworth filter\n10 Hz 12th order Butterworth filter\n\n\n% Generate filters\nLBW.highpass = designfilt('highpassiir', 'FilterOrder', 6, ...\n    'HalfPowerFrequency', 0.75, 'SampleRate', Fs)\n\nLBW.lowpass = designfilt('lowpassiir', 'FilterOrder', 12, ...\n    'HalfPowerFrequency', 10, 'SampleRate', Fs)\n\n% Filter Lmean\ntemp = filtfilt(LBW.highpass, Lmean);\nLmean_LBW = filtfilt(LBW.lowpass, temp);\n\n% Filter Rmean\ntemp = filtfilt(LBW.highpass, Rmean);\nRmean_LBW = filtfilt(LBW.lowpass, temp);\n\n% Filter again (only with the difference this time)\ntemp = filtfilt(LBW.highpass, (Lmean_LBW - Rmean_LBW));\nLR_LBW = filtfilt(LBW.lowpass, temp);\n\nFilter series 2: High Bandwidth\n\n0.75 Hz 6th order Butterworth filter\n50 Hz 12th order Butterworth filter\n\n\n% Generate filters\nHBW.highpass = designfilt('highpassiir', 'FilterOrder', 6, ...\n    'HalfPowerFrequency', 0.75, 'SampleRate', Fs)\n\nHBW.lowpass = designfilt('lowpassiir', 'FilterOrder', 12, ...\n    'HalfPowerFrequency', 50, 'SampleRate', Fs)\n\n% Filter Lmean\ntemp = filtfilt(HBW.highpass, Lmean);\nLmean_HBW = filtfilt(HBW.lowpass, temp);\n\n% Filter Rmean\ntemp = filtfilt(HBW.highpass, Rmean);\nRmean_HBW = filtfilt(HBW.lowpass, temp);\n\n% Filter again (only with the difference this time)\ntemp = filtfilt(HBW.highpass, (Lmean_HBW - Rmean_HBW));\nLR_HBW = filtfilt(HBW.lowpass, temp);\n\nNormalize Low Bandwidth Signal\n\nFirst take the first drivative\n\n\n\\[ x'[n] = \\frac{d}{dn}x[n], \\] where \\(x[n]\\) is the time domain representation of the LR mean signal\nLR_LBW_diff = diff(LR_LBW)/(Fs);\nThen normalize the difference representation\n\\[ x'[n] = \\frac{x'[n]}{\\text{max}\\|x'[n]\\|}\\]\nLR_LBW_norm = LR_LBW_diff./max(abs(LR_LBW_diff));\n\nGet the positive Shannon Energy envelope:\n\n\\[SEE[n] = -\\bigg( \\big&lt; ( &lt; x'_N[n], x'*_N[n] &gt; ), log( &lt; x'[n], x'*_N[n] &gt; ) \\big&gt; \\bigg)\\]\nwhen \\(x'*_N\\) is the complex conjugate. However, in most cases, this simplifies into real numbers as\n\\[SEE[n] = \\big&lt; x'[n]^2,\\ln(x'_N[n]^2)\\big&gt;\\]\nLR_LBW_SEE = -((LR_LBW_norm.^2).*log(LR_LBW_norm.^2));\nplot(LR_LBW_SEE(1:5000))\n\n\n\nShannon Entropy Envelope\n\n\nStep 10.2 : LR mean Peak Detection Round 1 ‚Äì SEE\n\nFind peak SEE (Assumption of maximum of 120 beats per minute supine heart rate.)\n\nbeatspermin = 120;\nprominence_factor = 0.1;\n%[pks, locs] =  findpeaks (LR_LBW_SEE, ...\n%    'MinPeakProminence', prominence_factor, ... \n%    'MinPeakDistance', (Fs/(beatspermin/60)));\n[pks, locs] =  findpeaks (LR_LBW_SEE, ...\n    'MinPeakDistance', (Fs/(beatspermin/60)));\n\nFind local minima and maxima for each peak\n\nrange2plot = 1:5000;\nt = 1:length(LR_LBW_SEE);\n\nsubplot(2,1,1)\nplot(t(range2plot), LR_LBW_SEE(range2plot))\nlocs_small = locs(and(locs &lt;= max(range2plot), locs &gt;= min(range2plot)));\nhold on\nplot(t(locs_small), pks(and(locs &lt;= max(range2plot), locs &gt;= min(range2plot))),  'r*')\nhold off\n\n\n\nPeak Shannon Entropy\n\n\n\nGet local minima and maxima for SEE peaks\n\nTolerance of \\(\\pm200\\) ms (don‚Äôt know if this is too much ‚Äì QRS complex takes .2 seconds (~200 ms))\ntol = 200; \n\nfor idx = 1:length(locs)\n    minloc = locs(idx) - tol;\n    if minloc &lt; 1\n        minloc = 1;\n    end\n    maxloc = locs(idx) + tol;\n    if maxloc &gt; length(LR_LBW_SEE)\n        maxloc = length(LR_LBW_SEE);\n    end\n    \n    [tmp, loc_tmp] = findpeaks(-LR_LBW(minloc:maxloc));\n    tmp = -tmp;\n    if length(tmp) &gt;= 1\n        minima.value(idx) = tmp(1);\n    else\n        minima.value(idx) = LR_LBW(locs(idx));\n    end\n    minima.loc(idx) = minloc + find(LR_LBW(minloc:maxloc) == minima.value(idx)) - 1;\n    \n    [tmp, loc_tmp] = findpeaks(LR_LBW(minloc:maxloc));\n    if isempty(tmp)\n        tmp = 0;\n    end\n    if length(tmp) &gt; 1\n        maxima.value(idx) = tmp(2);\n    elseif tmp == 0\n        maxima.value(idx) = max(LR_LBW(minloc:maxloc));\n    else\n        maxima.value(idx) = tmp(1);\n    end\n    maxima.loc(idx) = minloc + find(LR_LBW(minloc:maxloc) == maxima.value(idx)) - 1;\nend\n\nCompare values with average across all sets and flag all sets with at least one value greater than 1.5 standard deviations from mean.\n\nFirst the amplitude\n\n\nthreshstd = 1.5;\n\nmaxima.mean.value = mean(maxima.value);\nmaxima.std.value = std(maxima.value);\n\nmaxima2throw = or(maxima.value &gt;= maxima.mean.value + (threshstd*maxima.std.value), maxima.value &lt;= maxima.mean.value - (threshstd*maxima.std.value));\n\nminima.mean.value = mean(minima.value);\nminima.std.value = std(minima.value);\n\nminima2throw = or(minima.value &gt;= minima.mean.value + (threshstd*minima.std.value), minima.value &lt;= minima.mean.value - (threshstd*minima.std.value));\n- Then the temporal distance from SEE peak\nmaxima.dist.value = abs(locs - maxima.loc);\nmaxima.dist.mean = mean(maxima.dist.value);\nmaxima.dist.std = std(maxima.dist.value);\n\nmaximadist2throw = or(maxima.dist.value &gt;= maxima.dist.mean + (threshstd*maxima.dist.std), maxima.dist.value &lt;= maxima.dist.mean - (threshstd*maxima.dist.std));\n\nminima.dist.value = abs(locs - minima.loc);\nminima.dist.mean = mean(minima.dist.value);\nminima.dist.std = std(minima.dist.value);\n\nminimadist2throw = or(minima.dist.value &gt;= minima.dist.mean + (threshstd*minima.dist.std), minima.dist.value &lt;= minima.dist.mean - (threshstd*minima.dist.std));\n- And now temporal distance between minma and maxima\nmaximaminima.dist.value = abs(maxima.loc - minima.loc);\nmaximaminima.dist.mean = mean(maximaminima.dist.value);\nmaximaminima.dist.std = std(maximaminima.dist.value);\n\nmaximaminimadist2throw = or(maximaminima.dist.value &gt;= maximaminima.dist.mean + (threshstd*maximaminima.dist.std), maximaminima.dist.value &lt;= maximaminima.dist.mean - (threshstd*maximaminima.dist.std));\n- Now discard any peaks locations that are outside 1.5 standard deviations from the mean\npeaks2throw = (maxima2throw + maximadist2throw + maximaminimadist2throw + minima2throw + minimadist2throw &gt; 0);\n\nmaxima.thresh.value = maxima.value(~peaks2throw);\nmaxima.thresh.loc = maxima.loc(~peaks2throw);\nminima.thresh.value = minima.value(~peaks2throw);\nminima.thresh.loc = minima.loc(~peaks2throw);\n\n% Now plot them\nplot(t(range2plot), LR_LBW(range2plot))\nhold on\nlocs_small = locs(and(locs &lt;= max(range2plot), locs &gt;= min(range2plot)));\nplot(t(locs_small), LR_LBW(and(locs &lt;= max(range2plot), locs &gt;= min(range2plot))),  'r*');\nplot(t(maxima.thresh.loc(and(maxima.thresh.loc &lt;= max(range2plot), maxima.thresh.loc &gt;= min(range2plot)))), maxima.thresh.value(and(maxima.thresh.loc &lt;= max(range2plot), maxima.thresh.loc &gt;= min(range2plot))),  'g*')\nplot(t(minima.thresh.loc(and(minima.thresh.loc &lt;= max(range2plot), minima.thresh.loc &gt;= min(range2plot)))), minima.thresh.value(and(minima.thresh.loc &lt;= max(range2plot), minima.thresh.loc &gt;= min(range2plot))),  'b*')\nhold off\n\n\n\nPeak distances.\n\n\n% clear all figures\nclf\n- Remove any between peak distances with an interbeat interval greater than 1.5 seconds (~40 beats per min) and less than 0.5 seconds (~120 beats per minute).\nIBI.value = diff(minima.thresh.loc);\nIBI.thresh1 = 1.5*Fs;\nIBI.thresh2 = 0.5*Fs;\n\nIBI2keep = and(IBI.value &lt; IBI.thresh1, IBI.value &gt; IBI.thresh2);\n- From the remaining IBI, take the maximum of the mean IBI minus 2 standard deviations or 0.5 seconds. This is the window for creating the ballistocardiogram template.\nIBI.thresh.value = IBI.value(IBI2keep);\nIBI.thresh.mean = mean(IBI.thresh.value);\nIBI.thresh.std = std(IBI.thresh.value);\n\nIBIwindow = round(max(0.5*Fs, IBI.thresh.mean - (2*IBI.thresh.std)));\n- Compute average LR_LBW of IBIwindow size (like 'ERPs') centered on max peak\nIBI2keep4minima = logical([IBI2keep 0]);\nminima.thresh.valueIBI = minima.thresh.value(IBI2keep4minima);\nminima.thresh.locIBI = minima.thresh.loc(IBI2keep4minima);\n\nif mod(IBIwindow,2) ~= 0\n    IBIwindow = IBIwindow - 1;\nend\n\n\ncount = 1;\nfor i = 1:length(minima.thresh.locIBI)\n    minloc = minima.thresh.locIBI(i) - IBIwindow/2;\n    maxloc = minima.thresh.locIBI(i) + IBIwindow/2;\n    if minloc &lt; 1 | maxloc &gt; minima.thresh.locIBI(end) - IBIwindow/2;\n        continue\n    end\n    template.matrix(count,:) = LR_LBW(minloc:maxloc);\n    count=count+1;\nend\n\ntemplate.mean = mean(template.matrix);\ntemplate.std = std(template.matrix);\n- Compute BCG window.\n\nAdd path to the bounded line package. The bounded line package can be downloaded from [here](https://github.com/kakearney/boundedline-pkg/). Change path to fit your data. \naddpath('~/Documents/MATLAB/kakearney-boundedline-pkg-8179f9a/boundedline/')\naddpath('~/Documents/MATLAB/kakearney-boundedline-pkg-8179f9a/catuneven/')\naddpath('~/Documents/MATLAB/kakearney-boundedline-pkg-8179f9a/Inpaint_nans/')\naddpath('~/Documents/MATLAB/kakearney-boundedline-pkg-8179f9a/readmeExtras/')\naddpath('~/Documents/MATLAB/kakearney-boundedline-pkg-8179f9a/singlepatch/')\nboundedline(1-IBIwindow/2:1+IBIwindow/2, template.mean, template.std, 1-IBIwindow/2:1+IBIwindow/2, repmat(0, 1, length(template.std)), 0, 'r-')\n\nuthr = template.mean + template.std;\nlthr = template.mean - template.std;    \n\n\ncentre = IBIwindow/2+1;\n\ncutoff = find(uthr &lt; 0);\n\nmindistance = max(cutoff) - min(cutoff);\n\nGet cross correlations for each time window lag in data\n\nlngX = length(LR_LBW);\nlngY = length(template.mean);\nassert(lngX &gt;= lngY);\nlags = 0:(lngX-lngY);\nfor i = lags\n   c(i+1) = xcorr(LR_LBW(i+1:i+lngY) - mean(LR_LBW(i+1:i+lngY)), template.mean - mean(template.mean),0,'coeff');\nend\n\nclf\nplot(lags(range2plot),c(range2plot));\nxlabel('lags'); title('normalized cross-correlation');\n\n\n\nNormalized Cross Correlation\n\n\n[pks2, loc2] = findpeaks(c, 'MinPeakDistance', mindistance);\n\nqpkloc = loc2 + (maxima.thresh.loc(1) - loc2(1));\n\nplot(LR_LBW(1:5000))\nhold on\nplot(qpkloc(and(qpkloc &lt;= max(1:5000), qpkloc &gt;= min(1:5000))), LR_LBW(qpkloc(and(qpkloc &lt;= max(1:5000), qpkloc &gt;= min(1:5000)))), 'r*')\nhold off\n\n\nCross correlation error checking\n\nmeanIBI = movmean(diff(qpkloc),4) - mean(diff(qpkloc)); % center the data \ndeviationIBI = diff(qpkloc) - mean(diff(qpkloc));\n\nclf\nboundedline(1:length(meanIBI), meanIBI, 100, 'r-', 1:length(meanIBI), deviationIBI, 0, 'b-')\n\nFind the deviations greater than and less than a 100 ms (0.1 second) window around moving average\nqpkloc_new = qpkloc;\n\ndeviationIBIlocs = find(deviationIBI &gt; meanIBI + 100 | deviationIBI &lt; meanIBI - 100);\nif ~isempty(deviationIBIlocs)\n    disp('There are deviations outside threshold');\n    if length(deviationIBIlocs) &gt;= 1\n        bipolar = find(diff(deviationIBIlocs) == 1);\n        if ~isempty(bipolar)\n           for pk = 1:length(bipolar)\n                   [tmp3, loc3]  =  findpeaks(c(qpkloc(deviationIBIlocs(pk))-100:qpkloc(deviationIBIlocs(pk))+100));\n               if isempty(tmp3)\n                   continue\n               else\n                   [m,idx] = max(tmp3);\n                   qpkloc_new(deviationIBIlocs(pk)) = qpkloc(deviationIBIlocs(pk)) - 100 + loc3(idx);   \n                   % Done 2018/12/11 -- TODO: SHIFT PEAK POINT IN qpkloc to largest local peak in cross correlation signal\n               end\n           end\n        end\n    end\nend\n\nApply timing to larger bandwidth\n\n[HBWpks, HBWlocs] = findpeaks(LR_HBW, 'MinPeakDistance', mindistance);\ntemp = ismembertol(HBWlocs, qpkloc, 20, 'DataScale', 2); % put 0.01 second tolerance on match (although Rodriguez's dissertation doesn't specify what is meant by 'near') &lt;-- this is obviously wrong as it takes a vector of 900 and reduces it to 37. Still need to figure this one out.\nSPpeaks = HBWlocs; % HBWlocs(temp);\n\nplot(1:length(LR_HBW(range2plot)), LR_HBW(range2plot), SPpeaks(ismember(SPpeaks, range2plot)), LR_HBW(SPpeaks(ismember(SPpeaks, range2plot))), 'r*')\n\n\nSave to text file that needs minimal modifcations to be imported into EEGLAB\n\nT = table([SPpeaks' + start - 1], [repmat('sppeak', length(SPpeaks), 1)], ...\n    'VariableNames', {'latency', 'type'});\nwritetable(T,[srcdir nom],'Delimiter','\\t')\n\nDo qrs cleaning in EEGLAB using the FIMRIB tools.",
    "crumbs": [
      "Home",
      "MRI Methods",
      "EEG-fMRI",
      "EEG-fMRI Ballistocardiogram Cleaning (Rodriguez method)"
    ]
  },
  {
    "objectID": "mrimethods/anat/acpc-align.html",
    "href": "mrimethods/anat/acpc-align.html",
    "title": "Align AC PC to horizontal",
    "section": "",
    "text": "Align to the Anterior Commissure-Posterior Commisure Line\nIf you need help determining where the Anterior and Posterior Commisures are in your image, please see Commissural Pathways, available online, or Catani & Thiebaut de Schotten (2012), which is available from the UBC Library.\n\nDownload the acpc_align script from here. Be sure the code is in the folder where your participant‚Äôs structural scans are.\nMake the acpc_align.sh script executable.\n\nchmod 755 acpc_align.sh\n\nOpen your structural scan in your faviourite viewer. Here we are using FSLeyes.\n\n\n\n\nFSLeyes\n\n\n\nGet the X, Y and Z coordinates of the anterior commissure in voxel space by placing your cursor on the anterior commissure. The anterior commissure is located in the anterior wall of the third ventricle. It runs transversely anterior to the anterior columns of the fornix, above the basal forebrain and beneath the medial and ventral aspect of the anterior limb of the internal capsule. Save the X, Y, and Z coordinates.\n\n\n\n\nAnterior Commissure\n\n\n\nGet the X, Y, and Z coordinates of the posterior commissure in voxel space by placing your cursor on the posterior commissure. The posterior commissure is the inferior lamina or stalk of the pineal gland. Save the X, Y, and Z coordinates.\n\n\n\n\nPosterior Commissure\n\n\n\nIn your terminal (MacOS or Linux) run\n\nacpc_align subjectbrain.nii.gz -a x y z -p x y z\nto produce the realigned image for subject-specific to acpc alignment.\nIn the example, this is\nsh acpc_align.sh T1_reoriented.nii.gz -a 93 130 153 -p 93 98 152\n\n\n\nacpc aligned image\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Home",
      "MRI Methods",
      "Anat",
      "Align AC PC to horizontal"
    ]
  },
  {
    "objectID": "investigatorresources/index.html",
    "href": "investigatorresources/index.html",
    "title": "Investigator Resources",
    "section": "",
    "text": "No matching items\n\n Back to top",
    "crumbs": [
      "Home",
      "Investigator Resources"
    ]
  },
  {
    "objectID": "tutorials/git.html#what-is-version-control",
    "href": "tutorials/git.html#what-is-version-control",
    "title": "Git",
    "section": "What is Version Control?",
    "text": "What is Version Control?\nGit version control is an excellent application that allows you to keep track of changes to documents, and also to collaborate and work together. We use it a lot in the lab to save our code, share our code publicly with the science community, and to collaborate on projects.\nSoftware Carpentry has a good tutorial: Version Control with Git",
    "crumbs": [
      "Home",
      "Tutorials",
      "Git"
    ]
  },
  {
    "objectID": "tutorials/git.html#connecting-to-github-with-ssh",
    "href": "tutorials/git.html#connecting-to-github-with-ssh",
    "title": "Git",
    "section": "Connecting to Github with SSH",
    "text": "Connecting to Github with SSH\nIf you don't want to have to put your username and password in every time:\nNo Password Guide\nBasically, you will create a SSH key (or use an existing one):\nssh-keygen -t ed25519 -C \"your_email@example.com\"\nThen you will run:\ngh ssh-key add ~/.ssh/id_ed25519.pub\nNote, you will need to install gh, and run gh auth login\nFor gh auth login, pick:\n\nGitHub.com\nSSH\nyour key you want to upload\nLogin with a web browser",
    "crumbs": [
      "Home",
      "Tutorials",
      "Git"
    ]
  },
  {
    "objectID": "tutorials/git.html#start-a-repository",
    "href": "tutorials/git.html#start-a-repository",
    "title": "Git",
    "section": "Start a repository",
    "text": "Start a repository\nCreate a folder, enter the folder, then type:\ngit init .\nNow, head to your Github account and create a new repo\nName your new repo and click Create New Repository\nNow, in the command line type:\necho \"# Title\" &gt;&gt; README.md\ngit init\ngit add README.md\ngit commit -m \"first commit\"\ngit branch -M main\ngit remote add origin git@github.com:WeberLab/Title.git\ngit push -u origin main\nWhere Title is the name of your new repo",
    "crumbs": [
      "Home",
      "Tutorials",
      "Git"
    ]
  },
  {
    "objectID": "tutorials/git.html#update-a-repository",
    "href": "tutorials/git.html#update-a-repository",
    "title": "Git",
    "section": "Update a repository",
    "text": "Update a repository\nCheck status of remote origin (if any changes have been made on the Github):\ngit remote update\ngit pull",
    "crumbs": [
      "Home",
      "Tutorials",
      "Git"
    ]
  },
  {
    "objectID": "tutorials/git.html#clone-a-repository",
    "href": "tutorials/git.html#clone-a-repository",
    "title": "Git",
    "section": "Clone a repository",
    "text": "Clone a repository\nYou can clone a remote repository to create a local repository on your computer\nFor example,\ngit clone https://github.com/&lt;YourGithubAccountName&gt;/&lt;YourRepoName&gt;",
    "crumbs": [
      "Home",
      "Tutorials",
      "Git"
    ]
  },
  {
    "objectID": "tutorials/git.html#push-to-the-repository",
    "href": "tutorials/git.html#push-to-the-repository",
    "title": "Git",
    "section": "Push to the repository",
    "text": "Push to the repository\nYou can push any changes you make on your local repository to the remote repository. Make sure your current working directory is your local repository, then use the following commands:\ngit add &lt;filename&gt;\ngit commit -m \"Comment about what you added\"\ngit push origin &lt;branchname&gt;",
    "crumbs": [
      "Home",
      "Tutorials",
      "Git"
    ]
  },
  {
    "objectID": "tutorials/git.html#branches",
    "href": "tutorials/git.html#branches",
    "title": "Git",
    "section": "Branches",
    "text": "Branches\nYou can create branches to add or modify features of the master code.\nTo create a new branch, use command:\ngit checkout -b &lt;branchname&gt;\nThen you can add, commit and push to that branch as specified above. Note: use &lt;branchname&gt; main if you want to commit to main.\nYou can switch between branches using the command:\ngit checkout &lt;branchname&gt;\nYou can check what branch you are in using the command:\ngit branch\nSince branches are such an important topic, check out this website which is an excellent resource to understand them more intuitively: https://learngitbranching.js.org/",
    "crumbs": [
      "Home",
      "Tutorials",
      "Git"
    ]
  },
  {
    "objectID": "tutorials/docker.html#what-is-docker",
    "href": "tutorials/docker.html#what-is-docker",
    "title": "Docker",
    "section": "What is Docker",
    "text": "What is Docker\n\nan open-source project that automates the deployment of software applications inside containers by providing an additional layer of abstraction and automation of OS-level virtualization on Linux.\n\nLet‚Äôs begin with a lengthy analogy that will hopefully motivate the usefulness of Docker (and send light on the wordy definitions, as given above). I have summarised the analogy from this post, so have a look there if anything immediately below does not make sense.\nLet‚Äôs think about shipping containers (part of Docker logo). Before shipping containers were used, international trade was inefficient, workers would fill ships up with cargo of different sizes and requirements (e.g.¬†fragile or refrigerated). Depending on the size and shape of the ship vs.¬†the size and shape of the cargo a lot of the time the cargo was not compatible or would result in it perishing/breaking.\nThen came along containers,\n\nContainers were standardised so that loading and unloading became efficient.\nAnything that happened inside the container was the containers fault and not the ships. The merchants were responsible for securing everything inside.\nThe containers only need a sturdy enough ship to carry them (i.e.¬†they don‚Äôt care about model, shape or size).\n\nWhat happens if the ship sinks (i.e.¬†computer goes down, OS runs out of memory), unlike a shipping container where its contents are lost. You use a Dockerfile (analogous to a seed) to sprout up a new container. Re-creating the container is very easy, they can also be set-up so that backups are kept or that another container will be automatically birthed and carry on the task if one goes down.\nWhy hasn‚Äôt Docker taken over. Similar to international trade, shipping containers are very helpful, but they need someone to load, unload and ship. In the same way, the infrastructure necessary to fully take advantage of Docker is still on its way.\nTake away\n\nDocker containers package everything needed. e.g.¬†If you order a car building kit you would get a big container containing all the different parts in smaller boxes vs.¬†picking all individual parts at separate stores.\nPredictable environment. To re-make another car you can re-order the same package and be confident you‚Äôll get the exact same kit vs.¬†having to revisit all the stores again, likely to make a mistake.\nDocker isolated from other packages. e.g.¬†If you are building your car alongside a motorbike project you would two separate piles for your parts vs.¬†having all the parts in one pile and accidentally using a screw that may initially fit but ends up falling out and ruining the car.",
    "crumbs": [
      "Home",
      "Tutorials",
      "Docker"
    ]
  },
  {
    "objectID": "tutorials/docker.html#docker-vs.-virtual-machine",
    "href": "tutorials/docker.html#docker-vs.-virtual-machine",
    "title": "Docker",
    "section": "Docker vs.¬†Virtual Machine",
    "text": "Docker vs.¬†Virtual Machine\n\nBelow is a summary of the following post, I would encourage reading through the post for more detail.\n\nVirtual Machine\nA virtual machine is a virtual server that emulates a hardware server. i.e Hardware not in your computer is used to create a full computer environment that you can use to run an application. For example parallels can be used as an Apple user to run Windows applications on their Apple computer. NOTE: You will be in a Windows environment so you cannot run an Apple application but you can transfer files back and forth.\n\n\nDocker\nDocker uses containers that are platform independent (run across Windows and Linux). It‚Äôs main purpose is to run microservice applications, exactly what we need for neuroimaging applications. Docker is not a one-size-fits-all solution.\n\n\nDifferences\n\nDocker isolates individual applications vs.¬†VM isolating entire systems (i.e.¬†you can use containers inside VM‚Äôs)\nA Docker container can boot in less than a second vs.¬†VM can take up to a few minutes\nUse a Docker container to package code and its dependencies so that the code is easily shared with Dev, QA and IT.\nDocker has version control, can be compared to GitHub\n\nNOTE: Docker containers are lightweight compared to VM‚Äôs however, similar to having an empty or even unused container on a ship. It is advised to remove the container, remember (like a seed) it is easy to re-create the container if you have a Docker File.",
    "crumbs": [
      "Home",
      "Tutorials",
      "Docker"
    ]
  },
  {
    "objectID": "tutorials/docker.html#getting-started",
    "href": "tutorials/docker.html#getting-started",
    "title": "Docker",
    "section": "Getting Started",
    "text": "Getting Started\nDocker‚Äôs own Getting Started Guide",
    "crumbs": [
      "Home",
      "Tutorials",
      "Docker"
    ]
  },
  {
    "objectID": "tutorials/docker.html#install",
    "href": "tutorials/docker.html#install",
    "title": "Docker",
    "section": "Install",
    "text": "Install\nMac, Linux, and Windows",
    "crumbs": [
      "Home",
      "Tutorials",
      "Docker"
    ]
  },
  {
    "objectID": "tutorials/docker.html#terminology",
    "href": "tutorials/docker.html#terminology",
    "title": "Docker",
    "section": "Terminology",
    "text": "Terminology\n\nImages: The blueprints of our application which form the basis of containers.\nContainers: Created from Docker images and run the actual application.\nDocker Daemon: The background service running on the host that manages building, running and distributing Docker containers. The daemon is the process that runs in the operating system which clients talk to.\nDocker Client: The command line tool that allows the user to interact with the daemon.\nDocker Hub: A registry of Docker images (similar idea to GitHub or HomeBrew).",
    "crumbs": [
      "Home",
      "Tutorials",
      "Docker"
    ]
  },
  {
    "objectID": "tutorials/docker.html#set-up",
    "href": "tutorials/docker.html#set-up",
    "title": "Docker",
    "section": "Set-up",
    "text": "Set-up\nTest the install with\ndocker run hello-world",
    "crumbs": [
      "Home",
      "Tutorials",
      "Docker"
    ]
  },
  {
    "objectID": "tutorials/docker.html#commands",
    "href": "tutorials/docker.html#commands",
    "title": "Docker",
    "section": "Commands",
    "text": "Commands\nTo take an image from the Docker Hub\ndocker pull &lt;name-of-image&gt;\nTo check the images on the system\ndocker images\nTo run a Docker container based on the image. NOTE: Without any arguments, generally not much will happen. If you run a neuroimaging function, generally the function usage will be output.\ndocker run &lt;name-of-image&gt;\nHere is a helpful link for docker run options: link\nUsing the container ID output from ‚Äòdocker images‚Äô you can remove the container to free up space.\ndocker rm &lt;name-of-image&gt;\nIf the Docker container creates/manipulates files, unless otherwise specified these files are part of the container and will be removed when the container is. Read more about it here\nYou will need to pass the -v flag.\nFor example:\n\nInside the container the app creates /usr/src/app/logs\nTo map to host machine -v ~/logs:/usr/src/app/logs",
    "crumbs": [
      "Home",
      "Tutorials",
      "Docker"
    ]
  },
  {
    "objectID": "scienceresources/index.html",
    "href": "scienceresources/index.html",
    "title": "Science Resources",
    "section": "",
    "text": "No matching items\n\n Back to top",
    "crumbs": [
      "Home",
      "Science Resources"
    ]
  },
  {
    "objectID": "mriscanners/index.html",
    "href": "mriscanners/index.html",
    "title": "MRI Scanners",
    "section": "",
    "text": "No matching items\n\n Back to top",
    "crumbs": [
      "Home",
      "MRI Scanners"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "BCCH MRI Research Facility Wiki Page",
    "section": "",
    "text": "Overview\nThis page serves as a Wiki and collection of resources for users of BC Children‚Äôs MRI Research Facility\nYou can search this page using the magnifying glass in the top right üîç\nOr you can navigate using the sidebar on the left üëà\nIf you have MRI questions or want to connect with other BCCH MRI Research Facility users, you can use Mattermost to connect with us (similar to Slack or Microsoft Teams).\n\n\n\n\n Back to top"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "The BC Children‚Äôs Hospital MRI Research Facility is one of Canada‚Äôs top centres for pediatric brain mapping and imaging sciences research.\nA core facility of the BC Children‚Äôs Hospital‚Äôs Research Institute and affiliated with the University of British Columbia, the child-friendly environment of the MRI Research Facility is ideally situated to optimize opportunities for widespread research collaborations with the highly skilled staff found at BC Children‚Äôs Hospital and BC Women‚Äôs Hospital + Health Centre.\nThe MRI Research Facility features a GE Discovery MR750 3.0 Tesla MRI scanner for functional MRI, structural MRI and spectroscopy. The current scanner software version is DV26.0_R03.\nTogether, with our child-friendly MRI simulator, the MRI Research Facility provides an excellent platform for performing research studies on babies and young children.\n\n\n\n Back to top",
    "crumbs": [
      "Home",
      "About"
    ]
  },
  {
    "objectID": "tutorials/index.html",
    "href": "tutorials/index.html",
    "title": "Tutorials",
    "section": "",
    "text": "No matching items\n\n Back to top",
    "crumbs": [
      "Home",
      "Tutorials"
    ]
  },
  {
    "objectID": "tutorials/Python.html#scripts-vs.-modules",
    "href": "tutorials/Python.html#scripts-vs.-modules",
    "title": "Python",
    "section": "Scripts vs.¬†Modules",
    "text": "Scripts vs.¬†Modules\nIt's also important to know the difference between a Script and a Module:\nPython Scripts and Modules\nand\nCode Reuse: Functions and Modules\nA plain text .py file containing Python code that is intended to be directly executed by the user is usually called a script\nA plain text .py file, which contains Python code that is designed to be imported and used from another Python file, is called a module\n\nHow to write a simple script:\nOpen a text file and save it as a filename with the suffix .py:\nOne good program to use for this is Sublime Text. Check it out.\nOr better yet, Visual Studio Code\nOr in terminal:\nnano filename.py\n[note: nano is a built in text editor you can run from the command line. It's very handy]\nAt the top, it should say: #!/usr/bin/env python3\nthen your code. Here's an example:\n#!/usr/bin/env python3\n\nprint('Hello World!')\nAfter, you will have to assign execution permissions to your file:\nchmod +x filename.py\nYou can run the script from the directory with './' before the filename:\n./hello.py\nYou can also store this file in a Script folder, which you can tell Python to search in for scripts:\nexport PATH=\"$PATH:/usr/local/bin/python\"\nwhere /usr/local/bin/python is replaced with the path to the folder you want Python to look for your scripts\nAfter you set the path, you don't need to be in the directory where your script is, and you don't need to include the './' before the script name. You can just type the script name from any directory and it will run it:\nfilename.py\n\n\nHow to write a simple module:\nOpen a text file and write some simple code:\ndef greeting(name):\n  print(\"Hello, \" + name)\nSave this file as something like mymodule.py\nPlace this file in one of the Python paths (see above about scripts)\nTo see what paths Python is searching, start a python environment and type:\nimport sys\nsys.path\nNow import the module in python:\nimport mymodule\nThen run it:\nmymodule.greeting(\"Jonathan\")",
    "crumbs": [
      "Home",
      "Tutorials",
      "Python"
    ]
  },
  {
    "objectID": "tutorials/Python.html#install-upgrade-packages",
    "href": "tutorials/Python.html#install-upgrade-packages",
    "title": "Python",
    "section": "Install / Upgrade Packages",
    "text": "Install / Upgrade Packages\npip install &lt;package_name&gt;\npip install &lt;package_name&gt; --upgrade",
    "crumbs": [
      "Home",
      "Tutorials",
      "Python"
    ]
  },
  {
    "objectID": "tutorials/Python.html#troubleshooting",
    "href": "tutorials/Python.html#troubleshooting",
    "title": "Python",
    "section": "Troubleshooting",
    "text": "Troubleshooting\ninstead of pip, you might have to call it this way:\npython3 -m pip",
    "crumbs": [
      "Home",
      "Tutorials",
      "Python"
    ]
  },
  {
    "objectID": "tutorials/Python.html#numpy",
    "href": "tutorials/Python.html#numpy",
    "title": "Python",
    "section": "numpy",
    "text": "numpy\nnumpy is for numbers\nimport numpy as np",
    "crumbs": [
      "Home",
      "Tutorials",
      "Python"
    ]
  },
  {
    "objectID": "tutorials/Python.html#pandas",
    "href": "tutorials/Python.html#pandas",
    "title": "Python",
    "section": "pandas",
    "text": "pandas\npandas is for dataframes\nimport pandas as pd",
    "crumbs": [
      "Home",
      "Tutorials",
      "Python"
    ]
  },
  {
    "objectID": "tutorials/Python.html#scipy",
    "href": "tutorials/Python.html#scipy",
    "title": "Python",
    "section": "scipy",
    "text": "scipy\nSciPy provides algorithms for optimization, integration, interpolation, eigenvalue problems, algebraic equations, differential equations, statistics and many other classes of problems.",
    "crumbs": [
      "Home",
      "Tutorials",
      "Python"
    ]
  },
  {
    "objectID": "tutorials/Python.html#matplotlib",
    "href": "tutorials/Python.html#matplotlib",
    "title": "Python",
    "section": "matplotlib",
    "text": "matplotlib\nhttps://matplotlib.org/\nMatplotlib is for visualizations\n\nExample\nimport matplotlib.pyplot as plt\nfig, ax = plt.subplots()             # Create a figure containing a single Axes.\nax.plot([1, 2, 3, 4], [1, 4, 2, 3])  # Plot some data on the Axes.\nplt.show()                           # Show the figure.\n\n\n\nTransparent color\nhttps://stackoverflow.com/questions/62453018/matplotlib-colourmap-from-transparent\nhttps://stackoverflow.com/questions/22669704/correct-way-to-set-color-to-transparent-with-matplotlib-pcolormesh",
    "crumbs": [
      "Home",
      "Tutorials",
      "Python"
    ]
  },
  {
    "objectID": "tutorials/Python.html#plotly",
    "href": "tutorials/Python.html#plotly",
    "title": "Python",
    "section": "plotly",
    "text": "plotly\nPlotly‚Äôs Python graphing library makes interactive, publication-quality graphs.\nplotly.com/python/",
    "crumbs": [
      "Home",
      "Tutorials",
      "Python"
    ]
  },
  {
    "objectID": "tutorials/Python.html#jupyter",
    "href": "tutorials/Python.html#jupyter",
    "title": "Python",
    "section": "jupyter",
    "text": "jupyter\nThe Jupyter Notebook is the original web application for creating and sharing computational documents. It offers a simple, streamlined, document-centric experience.\njupyter.org/\npip install jupyter installs the Jupyter Notebook, JupyterLab, and the IPython Kernel",
    "crumbs": [
      "Home",
      "Tutorials",
      "Python"
    ]
  },
  {
    "objectID": "tutorials/Python.html#nilearn",
    "href": "tutorials/Python.html#nilearn",
    "title": "Python",
    "section": "nilearn",
    "text": "nilearn\nNilearn enables approachable and versatile analyses of brain volumes. It provides statistical and machine-learning tools, with instructive documentation & open community.\nnilearn.github.io/stable/index.html",
    "crumbs": [
      "Home",
      "Tutorials",
      "Python"
    ]
  },
  {
    "objectID": "tutorials/Python.html#nibabel",
    "href": "tutorials/Python.html#nibabel",
    "title": "Python",
    "section": "nibabel",
    "text": "nibabel\nhttps://nipy.org/nibabel/\n\nRead and write access to common neuroimaging file formats, including: ANALYZE (plain, SPM99, SPM2 and later), GIFTI, NIfTI1, NIfTI2, CIFTI-2, MINC1, MINC2, AFNI BRIK/HEAD, ECAT and Philips PAR/REC. In addition, NiBabel also supports FreeSurfer‚Äôs MGH, geometry, annotation and morphometry files, and provides some limited support for DICOM.\nNiBabel‚Äôs API gives full or selective access to header information (metadata), and image data is made available via NumPy arrays. For more information, see NiBabel‚Äôs documentation site and API reference.\n\nimport nibabel as nib",
    "crumbs": [
      "Home",
      "Tutorials",
      "Python"
    ]
  },
  {
    "objectID": "tutorials/Python.html#seaborn",
    "href": "tutorials/Python.html#seaborn",
    "title": "Python",
    "section": "seaborn",
    "text": "seaborn\nseaborn is a high level interface for drawing statistical graphics with Matplotlib. It aims to make visualization a central part of exploring and understanding complex datasets.\nseaborn.pydata.org/",
    "crumbs": [
      "Home",
      "Tutorials",
      "Python"
    ]
  },
  {
    "objectID": "tutorials/Python.html#nibabel-1",
    "href": "tutorials/Python.html#nibabel-1",
    "title": "Python",
    "section": "nibabel",
    "text": "nibabel\nRead and write access to common neuroimaging file formats\ngithub.com/nipy/nibabel",
    "crumbs": [
      "Home",
      "Tutorials",
      "Python"
    ]
  },
  {
    "objectID": "tutorials/Python.html#nipy",
    "href": "tutorials/Python.html#nipy",
    "title": "Python",
    "section": "nipy",
    "text": "nipy\nThe aim of NIPY is to produce a platform-independent Python environment for the analysis of functional brain imaging data using an open development model.\ngithub.com/nipy/nipy",
    "crumbs": [
      "Home",
      "Tutorials",
      "Python"
    ]
  },
  {
    "objectID": "tutorials/Python.html#nipype",
    "href": "tutorials/Python.html#nipype",
    "title": "Python",
    "section": "Nipype",
    "text": "Nipype\nNipype, an open-source, community-developed initiative under the umbrella of NiPy, is a Python project that provides a uniform interface to existing neuroimaging software and facilitates interaction between these packages within a single workflow. Nipype provides an environment that encourages interactive exploration of algorithms from different packages (e.g., SPM, FSL, FreeSurfer, AFNI, Slicer, ANTS), eases the design of workflows within and between packages, and reduces the learning curve necessary to use different packages.\ngithub.com/nipy/nipype",
    "crumbs": [
      "Home",
      "Tutorials",
      "Python"
    ]
  },
  {
    "objectID": "tutorials/Python.html#using-poetry",
    "href": "tutorials/Python.html#using-poetry",
    "title": "Python",
    "section": "Using poetry",
    "text": "Using poetry\nhttps://python-poetry.org/\n\nExample\npoetry init # press enter for defaults or make changes\npoetry add numpy # libraries you want to use\nYou should now have a file called pyproject.toml that looks like this:\n[tool.poetry]\nname = \"poetry\"\nversion = \"0.1.0\"\ndescription = \"\"\nauthors = [\"\"]\n\n[tool.poetry.dependencies]\npython = \"^3.8\"\nnumpy = \"^1.21.1\"\n\n[build-system]\nrequires = [\"poetry-core&gt;=1.0.0\"]\nbuild-backend = \"poetry.core.masonry.api\"\nIf you get an error when trying to install a package that says something like:\n\nThe current project's supported Python range (&gt;=3.10,&lt;4.0) is not compatible with some of the required packages Python requirement:\n\nstochastic requires Python &gt;=3.8,&lt;3.11, so it will not be satisfied for Python &gt;=3.11,&lt;4.0\n\nBecause no versions of stochastic match &gt;0.7.0,&lt;0.8.0\nand stochastic (0.7.0) requires Python &gt;=3.8,&lt;3.11, stochastic is forbidden.\nSo, because pythonncctoolbox depends on stochastic (^0.7.0), version solving failed.\n\nCheck your dependencies Python requirement: The Python requirement can be specified via the python or markers properties\n\nFor stochastic, a possible solution would be to set the `python` property to \"&gt;=3.10,&lt;3.11\"\n\nTry editing the pyproject.toml file so it reads:\n[tool.poetry.dependencies]\npython = \"&gt;=3.10,&lt;3.11\"\nNow type\npoetry update\nThen try to install your package again:\npoetry add stochastic\n\n\nJupyter\nhttps://hippocampus-garden.com/jupyter_poetry_pipenv/\npoetry add -D jupyter # libraries for development use only\nnow just run\npoetry run jupyter notebook",
    "crumbs": [
      "Home",
      "Tutorials",
      "Python"
    ]
  },
  {
    "objectID": "tutorials/Python.html#using-virtualenv",
    "href": "tutorials/Python.html#using-virtualenv",
    "title": "Python",
    "section": "Using virtualenv",
    "text": "Using virtualenv\nFirst make sure virtualenv is installed:\npip install virtualenv\nNext create a virtual environment\nvirtualenv .venv -p python\nwhere .venv is what I‚Äôve called my virtual environment (and it will place it in the current directory I‚Äôm in); and -p python tells the computer which python to use (it will be whatever is which python\nNow activate this environment:\nsource .venv/bin/activate\nNow when you type which python it should show your venv path\nAlso: which pip should do the same\nTo deactivate:\ndeactivate\nInclude in jupyter notebook:\npython -m ipykernel install --user --name=yourvenvname",
    "crumbs": [
      "Home",
      "Tutorials",
      "Python"
    ]
  },
  {
    "objectID": "tutorials/Python.html#install",
    "href": "tutorials/Python.html#install",
    "title": "Python",
    "section": "Install",
    "text": "Install\ncd ~/Downloads\nwget --quiet https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\nbash Miniconda3-latest-Linux-x86_64.sh -b -p &lt;dir&gt;\nwhere &lt;dir&gt; is where you want to install (e.g.¬†$HOME/miniconda3)\nthen\nsource &lt;dir&gt;/bin/activate\nUpdate\nconda update conda -y",
    "crumbs": [
      "Home",
      "Tutorials",
      "Python"
    ]
  },
  {
    "objectID": "tutorials/Python.html#conda-environments",
    "href": "tutorials/Python.html#conda-environments",
    "title": "Python",
    "section": "Conda Environments",
    "text": "Conda Environments\n\nUsing environments are highly recommended as a best practice for running scripts.\nConda environments are easier set-up than pip environments\nConda checks to makes sure all dependancies are met at all times, where as pip does not.\n\nExample\nconda create --name my-python38environment python=3.8\nTo activate:\nconda activate my-python38environment\nTo deactivate:\nconda deactivate\n\nBest practices\nTo list the conda environments:\nconda info --envs\nTo install a specific package into a specific environment\nconda install -n &lt;env_name&gt; &lt;package&gt;\ne.g. conda install -n first_r_python_env numpy\nSometimes you will have to specify a specific channel (similar idea to a repository) as not all packages are in the default conda channel.\nTry to install from the default channel or 'channel-forge' (a community managed channel) as these are the best managed channels.\nconda install -c conda-forge -n &lt;env_name&gt; &lt;package&gt;\nA list of the more common packages and where I found them.\n\nconda install -n &lt;env_name&gt; numpy\nconda install -n &lt;env_name&gt; pandas\nconda install -n &lt;env_name&gt; matplotlib\nconda install -n &lt;env_name&gt; seaborn\nconda install -c conda-forge -n &lt;env_name&gt; rpy2\nconda install -c conda-forge -n &lt;env_name&gt; statsmodels\nconda install -c conda-forge -n &lt;env_name&gt; nilearn\nconda install -c intel -n &lt;env_name&gt; scikit-learn\n\nYour .conda directory may get very large if you install multiple packages and create many virtual Conda environments. Make sure to clean the Conda cache and clean unused packages with:\nconda clean --all\nClean unused Conda environments by first listing the environments with:\nconda env list\n, and then removing unused ones:\nconda env remove --name &lt;yourenvironmentname&gt;\nYou can build Conda environments in different locations to save space on your home directory. You can use the ‚Äîprefix flag when building your environment. For example:\nconda create myenv --prefix=/work/&lt;mygroup&gt;/&lt;mydirectory&gt;",
    "crumbs": [
      "Home",
      "Tutorials",
      "Python"
    ]
  },
  {
    "objectID": "tutorials/Python.html#troubleshooting-1",
    "href": "tutorials/Python.html#troubleshooting-1",
    "title": "Python",
    "section": "Troubleshooting",
    "text": "Troubleshooting\nIf you'd prefer that conda's base environment not be activated on startup, set the auto_activate_base parameter to false:\nconda config --set auto_activate_base false",
    "crumbs": [
      "Home",
      "Tutorials",
      "Python"
    ]
  },
  {
    "objectID": "tutorials/Python.html#nipype-1",
    "href": "tutorials/Python.html#nipype-1",
    "title": "Python",
    "section": "NiPype",
    "text": "NiPype\nNiPype stands for Neuroimaging in Pythong Pipelines and Interfaces (link)\n\nFSL\nFSL can be run from NiPype\nimport nipype.interfaces.fsl as fsl\nHead here for documentation\nExample:\nfrom nipype.interfaces.fsl import Merge\nmerger = Merge()\nmerger.inputs.in_files = ['functional2.nii', 'functional3.nii']\nmerger.inputs.dimension = 't'\nmerger.inputs.output_type = 'NIFTI_GZ'\nmerger.cmdline\n'fslmerge -t functional2_merged.nii.gz functional2.nii functional3.nii'\nmerger.inputs.tr = 2.25\nmerger.cmdline\n'fslmerge -tr functional2_merged.nii.gz functional2.nii functional3.nii 2.25'",
    "crumbs": [
      "Home",
      "Tutorials",
      "Python"
    ]
  },
  {
    "objectID": "tutorials/Python.html#curve-and-surface-fits",
    "href": "tutorials/Python.html#curve-and-surface-fits",
    "title": "Python",
    "section": "Curve and Surface fits",
    "text": "Curve and Surface fits\nAdding a line or curve of best fit is a quick way of visualising the relationship between data.\nWe have to be mindful of the different ways of fitting data; you can underfit but also overfit.\nPackages to import\nimport numpy as np\nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy import stats\nfrom scipy.optimize import curve_fit\nimport pickle\nfrom scipy.stats import spearmanr\nfrom scipy.stats import pearsonr\nimport matplotlib.animation as animation",
    "crumbs": [
      "Home",
      "Tutorials",
      "Python"
    ]
  },
  {
    "objectID": "tutorials/Python.html#d-function-fit",
    "href": "tutorials/Python.html#d-function-fit",
    "title": "Python",
    "section": "2d function fit",
    "text": "2d function fit\nYou can plot a straight line fit quite easily with modules such as seaborn, you can even fit data with higher order polynomials\nBut for custom control over the fitting function I have provided a basic example script.\nNOTE: It will also produce a residual plot which is good visual way to check the 'goodness' of the fit.\ndef 2d_fit_residual(data, x_name, y_name):\n    \"\"\"\n    2d_fit_residual outputs a curve fitted plot of the input data points based on theoretical fitting function fit_function()\n    it also outputs a residual graph.\n\n    :data: np.array x,y data inputs expected to be in format [[x1, y1], [x2, y2], [x3, y3], ...]\n    :x_name: str x-axis variable name\n    :y_name: str y-axis variable name\n    :return: curve fitted plot and residual graph\n    \"\"\" \n\n    X = data[:,0]\n    Y = data[:,1]\n\n    ######################################################################\n    # custom function. If you change the number of parameters, you will \n    # need to update the guesses variable and any calls to fit_function()\n    ######################################################################\n    def fit_function(X_var, Y1, Y2, C):\n        return Y1*X_var**2 + Y2*X_var + C\n\n    ######################################################################\n    # curve fit part\n    ######################################################################\n    guesses = (1, 1, 1)\n    params, pcov = curve_fit(fit_function, X, Y, guesses, maxfev=10**8)\n\n    ######################################################################\n    # data scatter graph plot\n    ######################################################################\n    fig = plt.figure()\n    ax = plt.axes()\n    plt.title('{} vs. {}'.format(y_name, x_name))\n    plt.xlabel('{}'.format(x_name))\n    plt.ylabel('{}'.format(y_name))\n    ax.scatter(X, Y, c='green')\n\n    ######################################################################\n    # correlation coefficients. Pearsons assumes linear, Spearmans does not\n    ######################################################################\n    corr, _ = spearmanr(X, Y)\n    legs = 'Spearmans correlation: %.3f' % corr\n    # corrlin, _ = pearsonr(X, Y)\n    # legslin = 'Pearsons correlation: %.3f' % corr\n\n    ######################################################################\n    # plot fit onto graph\n    ######################################################################\n    xtheory = np.linspace(min(X), max(X), 10000)\n    z_theory = fit_function(xtheory, params[0], params[1], params[2])\n    ax.plot(xtheory, z_theory, label = legs)\n    ax.legend(loc = 'best')\n    plt.show()\n\n    ######################################################################\n    # residual to check fit\n    ######################################################################\n    y_theory = fit_function(np.array((X)), params[0], params[1], params[2])\n    y_diff = y_theory - Y\n    fig = plt.figure()\n    ax = plt.axes()\n    ax.scatter(X, y_diff, c='red', marker='x')\n    ax.plot(np.array((min(X), max(X))), np.array((0,0)))\n    plt.title('Residual graph of difference between model and data')\n    plt.xlabel('{}'.format(x_name))\n    plt.ylabel('Measureed - Theoretical {}'.format(y_name))\n    plt.show()\nThe reason for the odd input data numpy shape is because of pandas data frames. To create a numpy array for this function from your data frame\n2d_fit_input = df[['x_var', 'y_var']].to_numpy()",
    "crumbs": [
      "Home",
      "Tutorials",
      "Python"
    ]
  },
  {
    "objectID": "tutorials/Python.html#d-function-fit-1",
    "href": "tutorials/Python.html#d-function-fit-1",
    "title": "Python",
    "section": "3d function fit",
    "text": "3d function fit\ndef scatter_3d(data, Z, x_name, y_name, z_name):\n\n    \"\"\"\n    scatter_3d outputs a 3d surface fitted plot of the input data points based \n    on theoretical fitting function fit_function()\n    Will also retrun a pickle of the 3d plot in the directory you run this\n    script from. \n\n    :data: np.array x,y data inputs expected to be in format [[x1, y1], [x2, y2], [x3, y3], ...]\n    :Z: np.array z data inputs expected to be in format [z1, z2, z3, ...]\n    :x_name: str x-axis variable name\n    :y_name: str y-axis variable name\n    :z_name: str z-axis variable name\n    :return: surface fitted plot and a pickle of the surface fitted plot \n    \"\"\" \n\n    X = data[:,0]\n    Y = data[:,1]\n    def fit_function(data, X1, X2, X3, Y1, Y2, Y3, XY, C1, C2):\n        x = data[:,0]\n        y = data[:,1]\n        return -np.sqrt(X2*x + Y2*y + C1) + np.sqrt(X2*x + Y2*y + C1-(X1*x**2 + Y1*y**2 + XY*x*y + X3*x + Y3*y + C2))\n\n    ######################################################################\n    # curve fit part\n    ######################################################################\n    guesses = (-0.5,  100,  100,  -0.5, 1, 1, 0.0001, 100, -100)\n    params, pcov = curve_fit(fit_function, data, Z, guesses, maxfev=10**8)\n    print('Params = {}'.format(params))\n\n    ######################################################################\n    # 3d scatter graph plot\n    ######################################################################\n    fig = plt.figure()\n    ax = plt.axes(projection = '3d')\n    ax.set_title('{} vs. {} vs. {}'.format(z_name, y_name, x_name))\n    ax.set_xlabel('{}'.format(x_name))\n    ax.set_ylabel('{}'.format(y_name))\n    ax.set_zlabel('{}'.format(z_name))\n    ax.scatter(X, Y, Z, c='red', marker='x', label='data points')\n    ax.legend(loc='upper left')\n\n    ######################################################################\n    # plot fit onto 3d scatter\n    ######################################################################\n    X1 = params[0]\n    X2 = params[1]\n    X3 = params[2]\n    Y1 = params[3]\n    Y2 = params[4]\n    Y3 = params[5]\n    XY = params[6]\n    C1 = params[7]\n    C2 = params[8]\n\n    xtheory = np.linspace(1.05*min(X), max(X), 4000)\n    ytheory = np.linspace(1*min(Y), max(Y), 4000)\n    x_grid, y_grid = np.meshgrid(xtheory, ytheory)\n\n    x = x_grid\n    y = y_grid\n    z_grid = -np.sqrt(X2*x + Y2*y + C1) + np.sqrt(X2*x + Y2*y + C1-(X1*x**2 + Y1*y**2 + XY*x*y + X3*x + Y3*y + C2))\n\n    ax.plot_surface(x_grid, y_grid, z_grid)\n    ax.set_xlim(min(X), max(X))\n    ax.set_ylim(min(Y), max(Y))\n    ax.set_zlim(min(Z), max(Z))\n\n    #Change name if you want the pickle saved in a different folder\n    pickle.dump(fig, open('FigureObject.fig.pickle', 'wb'))\n\n    def rotate(angle):\n        ax.view_init(azim=angle)\n\n    #making an animation\n    rot_animation = animation.FuncAnimation(fig, rotate, frames=np.arange(0, 362, 2), interval=100)\n    rot_animation.save('rotation.gif', dpi=80, writer='imagemagick')\n\n    plt.show()\nSaving the 3d graph in a Pickle allows you send this by email and the receiver can open it and manipulate it vs.¬†sending a stationary 2d plot.\nTo open a pickle\nimport pickle\npath='/Users/johanndrayne/Documents/Python/FigureObject.fig.pickle'\nfigx = pickle.load(open(path, 'rb'))\nfigx.show()",
    "crumbs": [
      "Home",
      "Tutorials",
      "Python"
    ]
  },
  {
    "objectID": "tutorials/Python.html#read-matlab-.mat-files",
    "href": "tutorials/Python.html#read-matlab-.mat-files",
    "title": "Python",
    "section": "Read Matlab .mat files:",
    "text": "Read Matlab .mat files:\nsee this thread: https://stackoverflow.com/questions/874461/read-mat-files-in-python\nimport scipy.io\nmat = scipy.io.loadmat('file.mat')\nor\nimport numpy as np\nimport h5py\nf = h5py.File('somefile.mat','r')\ndata = f.get('data/variable1')\ndata = np.array(data) # For converting to a NumPy array",
    "crumbs": [
      "Home",
      "Tutorials",
      "Python"
    ]
  },
  {
    "objectID": "studentresources/index.html",
    "href": "studentresources/index.html",
    "title": "Student Resources",
    "section": "",
    "text": "No matching items\n\n Back to top",
    "crumbs": [
      "Home",
      "Student Resources"
    ]
  },
  {
    "objectID": "mrimethods/index.html",
    "href": "mrimethods/index.html",
    "title": "MRI Methods",
    "section": "",
    "text": "Align AC PC to horizontal\n\n\n\n\n\n\nanat\n\n\nshell\n\n\ncode\n\n\nvisualization\n\n\nalignment\n\n\n\nTranslate your structural scans to AC-PC alignment for visualization and display.\n\n\n\n\n\nDec 4, 2024\n\n\nDanny Kim\n\n\n\n\n\n\n\n\n\n\n\n\nEEG-fMRI Data Cleaning & Forward Solution\n\n\n\n\n\n\neeg-fmri\n\n\ncode\n\n\nmatlab\n\n\neeglab\n\n\nmne\n\n\nfreesurfer\n\n\npreprocessing\n\n\neeg\n\n\n\nReverse engineered code from Rodriguez (2016) for removal of the ballistocardiogram artifacts from EEG-fMRI data when the ECG fails to give a good signal. This code requires Matlab and the Signal Processing Toolbox.\n\n\n\n\n\nFeb 13, 2024\n\n\nLynne Williams\n\n\n\n\n\n\n\n\n\n\n\n\nEEG-fMRI Ballistocardiogram Cleaning (Rodriguez method)\n\n\n\n\n\n\neeg-fmri\n\n\ncode\n\n\nmatlab\n\n\npreprocessing\n\n\neeg\n\n\n\nReverse engineered code from Rodriguez (2016) for removal of the ballistocardiogram artifacts from EEG-fMRI data when the ECG fails to give a good signal. This code requires Matlab and the Signal Processing Toolbox.\n\n\n\n\n\nJul 11, 2018\n\n\nLynne Williams\n\n\n\n\n\n\nNo matching items\n\n Back to top",
    "crumbs": [
      "Home",
      "MRI Methods"
    ]
  },
  {
    "objectID": "mrimethods/eeg-fmri/index.html",
    "href": "mrimethods/eeg-fmri/index.html",
    "title": "EEG-fMRI",
    "section": "",
    "text": "Back to top"
  },
  {
    "objectID": "mrimethods/eeg-fmri/gradient-removal.html",
    "href": "mrimethods/eeg-fmri/gradient-removal.html",
    "title": "EEG-fMRI Data Cleaning & Forward Solution",
    "section": "",
    "text": "The purpose of this procedure is to outline the steps necessary for cleaning magnetic resonance (MR) and ballistocardiogram (BCG) artifacts from EEG data obtained during simultaneous EEG-fMRI recordings. The efficacy of multimodal imaging can be significantly compromised without proper artifact removal. Hence, this procedure is crucial for improving the quality and interpretability of EEG data that is collected in conjunction with fMRI studies, particularly in clinical and research settings in the field of medicine.\n\n\nThe procedure for cleaning MR and BCG artifacts from EEG data can be summarized in three main steps:\n\nArtifact Identification: Detecting and marking the artifacts within the EEG data that stem from MR and BCG sources.\nArtifact Removal: Implementing algorithms and techniques designed to exclude or minimize the intrusion of identified artifacts.\nData Validation: Assessing the cleaned EEG data to confirm the efficacy of artifact removal and ensuring the integrity of the signal for further analysis.\n\nThis high-level overview provides a foundational understanding of the procedural steps involved without delving into complex technicalities.\n\n\n\n\n\nUse the subject id from the MR scanner EEG-fMRI session.\ncd BHBMEG&lt;subject_id&gt;\n\n\n\nPut the MRI data in BIDS format using your favourite BIDS conversion tool. I recommend dcm2bids. You can find more information at https://unfmontreal.github.io/Dcm2Bids/3.1.1/. Be sure that the subject is the root BIDS directory (i.e., only one subject in the BIDS directory) to keep the analysis as a N = 1 study.\nInstall anaconda if you haven‚Äôt already done so. Go to https://www.anaconda.com/download. Follow the install directions for your workstation and operating system.\nOpen a Terminal window. Check your Python version. At the command prompt, type\nwhich python\nIf the command should return a path with anaconda3 in it. For example,\n/Users/lj/anaconda3/bin/python\nCreate a python environment for dcm2bids. In a text file called environment.yml copy the following:\nname: dcm2bids\\\nchannels:\\\n- conda-forge\\\ndependencies:\\\n- python\\&gt;=3.7\\\n- dcm2niix\\\n- dcm2bids\nand in Terminal create the environment:\nconda env create --file environment.yml*\nActivate your new python environment. By running\nconda activate dcm2bids\nTest your dcm2bids installation.\ndcm2bids *\\--help*\nYou should get the help file for dcm2bids:\nusage: dcm2bids [-h] -d DICOM_DIR [DICOM_DIR ...] -p PARTICIPANT [-s SESSION]  \n¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬† -c CONFIG [-o OUTPUT_DIR] [_--auto_extract_entities]_¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬† [_--bids_validate] [--force_dcm2bids] [--skip_dcm2niix]_¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬† [_--clobber] [-l {DEBUG,INFO,WARNING,ERROR,CRITICAL}] [-v]_Reorganising NIfTI files from dcm2niix into the Brain Imaging Data Structure  \n  \noptions:  \n¬† -h, _--help¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬† show this help message and exit_¬† -d DICOM_DIR [DICOM_DIR ...], _--dicom_dir DICOM_DIR [DICOM_DIR ...]_¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬† DICOM directory(ies) or archive(s) (tar, tar.bz2, tar.gz or zip).  \n¬† -p PARTICIPANT, _--participant PARTICIPANT_¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬† Participant ID.  \n¬† -s SESSION, _--session SESSION_¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬† Session ID. []  \n¬† -c CONFIG, _--config CONFIG_¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬† JSON configuration file (see example/config.json).  \n¬† -o OUTPUT_DIR, _--output_dir OUTPUT_DIR_¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬† Output BIDS directory. [/Users/lj]¬† _--auto_extract_entities_¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬† If set, it will automatically try to extract entityinformation [task, dir, echo] based on the suffix and datatype. [False]¬† _--bids_validate¬†¬†¬†¬†¬†¬† If set, once your conversion is done it will check if your output folder is BIDS valid. [False]_¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬† bids-validator needs to be installed check: https://github.com/bids-standard/bids-validator_#quickstart_¬† _--force_dcm2bids¬†¬†¬†¬†¬† Overwrite previous temporary dcm2bids output if it exists._¬† _--skip_dcm2niix¬†¬†¬†¬†¬†¬† Skip dcm2niix conversion. Option -d should contains NIFTI and json files._¬† _--clobber¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬† Overwrite output if it exists._¬† -l {DEBUG,INFO,WARNING,ERROR,CRITICAL}, _--log_level {DEBUG,INFO,WARNING,ERROR,CRITICAL}_¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬† Set logging level to the console. [INFO]  \n¬† -v, _--version¬†¬†¬†¬†¬†¬†¬†¬† Report dcm2bids version and the BIDS version._Documentation at https://unfmontreal.github.io/Dcm2Bids/\nMake a directory for your BIDS root directory:\nmkdir BIDS\\\ncd BIDS\nCreate the scaffold for your BIDS root directory:\ndcm2bids_scaffold -o BHBMEG&lt;subject_id\\&gt;\ncd BHBMEG&lt;subject_id&gt;\nDownload your MRI data from XNAT for BHBMEG&lt;subject_id&gt;.\nPut the MRI data in the sourcedata folder created by the scaffold.\nunzip \\&lt;xnat-username\\&gt;-\\&lt;download-date\\&gt;\\_\\&lt;download-time\\&gt;.zip -d\nsourcedata/\nFor example,\nunzip lwilliams-20240109_134304.zip -d sourcedata/\nChange the folder name to mri.\nmv ./sourcedata/\\&lt;xnat-username\\&gt;-\\&lt;download-date\\&gt;\\_\\&lt;download-time\\&gt;\nmri\nFor example,\nmv ./sourcedata/ lwilliams-20240109_134304 mri\nMove any additional MRI sessions into the mri folder (e.g., the structural scans from a corresponding BHBEP session).\nCreate a new .config file in the code folder of your subject‚Äôs BIDS folder. You can use any code editor, but here we will use nano.\ncd \\&lt;path to subject's BIDS directory\\&gt;\nnano code/dcm2bids_config.json\nIn the dcm2bids_config.json file in the editor window, add the following:\n{\n\"descriptions\": [ ]\n}\nChange directory back to the sourcedata/mri folder:\ncd &lt;path to BHBMEG&lt;subject_id&gt; directory&gt;/sourcedata/mri\nRun the dcm2bids_helper function:\ndcm2bids_helper -d . \nNote that the period indicates to run dcm2bids_helper function in the current directory. It will create a folder in that directory call tmp_dcm2bids/helper. Here you will find your NIFTI files using the names given by the scanner console. You can check what is in the folder by running ls:\nls tmp_dcm2bids/helper \nFor each scan, there will be 2 files: the NIFTI file and a .json sidecar:\nls tmp/dcm2bids/helper/*\n003\\_.\\_RESEARCH\\_-\\_BHBEP_20190314111207.json\n003\\_.\\_RESEARCH\\_-\\_BHBEP_20190314111207.nii.gz\n003\\_.\\_RESEARCH\\_-\\_BHBMEG_20190507142627.json\n003\\_.\\_RESEARCH\\_\\_BHBMEG_20190507142627.nii.gz\n004\\_.\\_RESEARCH\\_-\\_BHBMEG_20190507142627.json\n004\\_.\\_RESEARCH\\_-\\_BHBMEG_20190507142627.nii.gz\n005\\_.\\_RESEARCH\\_-\\_BHBMEG_20190507142627.json\n005\\_.\\_RESEARCH\\_-\\_BHBMEG_20190507142627.nii.gz\n006\\_.\\_RESEARCH\\_-\\_BHBMEG_20190507142627.json\n006\\_.\\_RESEARCH\\_-\\_BHBMEG_20190507142627.nii.gz\n006\\_.\\_RESEARCH\\_-\\_BHBMEG_20190507142627.nii.gz\n007\\_.\\_RESEARCH\\_-\\_BHBMEG_20190507142627.json\n007\\_.\\_RESEARCH\\_-\\_BHBMEG_20190507142627.nii.gz\n009\\_.\\_RESEARCH\\_-\\_BHBMEG_20190507142627.json\n009\\_.\\_RESEARCH\\_-\\_BHBMEG_20190507142627.nii.gz\n010\\_.\\_RESEARCH\\_-\\_BHBMEG_20190507142627.json\n010\\_.\\_RESEARCH\\_-\\_BHBMEG_20190507142627.nii.gz\n011\\_.\\_RESEARCH\\_-\\_BHBMEG_20190507142627.json\n011\\_.\\_RESEARCH\\_-\\_BHBMEG_20190507142627.nii.gz\n012\\_.\\_RESEARCH\\_-\\_BHBMEG_20190507142627.json\n012\\_.\\_RESEARCH\\_-\\_BHBMEG_20190507142627.nii.gz\n013\\_.\\_RESEARCH\\_-\\_BHBMEG_20190507142627.json\n013\\_.\\_RESEARCH\\_-\\_BHBMEG_20190507142627.nii.gz\nYou will use the information in the sidecar file to put your data into BIDS format.\nTo populate the config file, you need to inspect each of the sidecar files one at a time to make sure there is a unique match for the acquisitions. You can use the ‚ÄúSeriesDescription‚Äù field to help you.\ncat ./sourcedata/mri/tmp_dcm2bids/helper/\nChange directories into the helper folder:\ncd &lt;Path to BHBMEG&lt;subject_id&gt; folder&gt;/sourcedata/mri/tmp_dcm2bids/helper\nFind the Series Description using grep. For example,\ngrep SeriesDescription *.json\nwhich returns the lines:\n003_._RESEARCH_-_BHBEP_20190314111207.json: \"SeriesDescription\": \"SAG MPRAGE PROMO 0.9x0.9x0.9\",\n003_._RESEARCH_-_BHBMEG_20190507142627.json: \"SeriesDescription\": \"fMRI Resting State\",\n004_._RESEARCH_-_BHBMEG_20190507142627.json: \"SeriesDescription\": \"fMRI Resting State\",\n005_._RESEARCH_-_BHBMEG_20190507142627.json: \"SeriesDescription\": \"fMRI Resting State\",\n006_._RESEARCH_-_BHBMEG_20190507142627.json: \"SeriesDescription\": \"fMRI Resting State\",\n007_._RESEARCH_-_BHBMEG_20190507142627.json: \"SeriesDescription\": \"fMRI Resting State\",\n009_._RESEARCH_-_BHBMEG_20190507142627.json: \"SeriesDescription\": \"fMRI Hand Stim\",\n010_._RESEARCH_-_BHBMEG_20190507142627.json: \"SeriesDescription\": \"fMRI Resting State\",\n011_._RESEARCH_-_BHBMEG_20190507142627.json: \"SeriesDescription\": \"fMRI Resting State\",\n012_._RESEARCH_-_BHBMEG_20190507142627.json: \"SeriesDescription\": \"fMRI Resting State\",\n013_._RESEARCH_-_BHBMEG_20190507142627.json: \"SeriesDescription\": \"SAG FSPGR 3D .9X.9X.9\"\nWe can add it to our config file.\n{\n\"descriptions\\\": [\n  {\n    \"datatype\": \"anat\",\n    \"suffix\": \"T1w\",\n    \"custom_entities\": \"ses-brainmap\",\n    \"criteria\": {\n      \"SeriesDescription\": \"SAG MPRAGE PROMO 0.9x0.9x0.9\",\n      \"SeriesNumber\": \"3\"\n      }\n    }\n  ]\n}\nMake sure that the ‚Äúcriteria‚Äù together identify only one MRI sequence. Look at SeriesNumber to differentiate the files. Continue until you have completed this exercise for all runs for all sequences. You should get something that looks like below:\n{  \n¬† \"descriptions\": [  \n¬†¬†¬† {  \n¬†¬†¬†¬†¬† \"datatype\": \"anat\",  \n¬†¬†¬†¬†¬† \"suffix\": \"T1W\",  \n¬†¬†¬†¬†¬† \"custom_entities\": \"ses-brainmap\",  \n¬†¬†¬†¬†¬† \"criteria\":  \n¬†¬†¬†¬†¬†¬†¬† {  \n¬†¬†¬†¬†¬†¬†¬†¬†¬† \"SeriesDescription\": \"SAG MPRAGE PROMO 0.9x0.9x0.9\",  \n¬†¬†¬†¬†¬†¬†¬†¬†¬† \"SeriesNumber\": \"3\"¬†¬†¬†¬†¬†¬†¬† }  \n¬†¬†¬† },  \n¬†¬†¬† {  \n¬†¬†¬†¬†¬† \"datatype\": \"anat\",  \n¬†¬†¬†¬†¬† \"suffix\": \"T1W\",  \n¬†¬†¬†¬†¬† \"custom_entities\": \"ses-eegfmri\",  \n¬†¬†¬†¬†¬† \"criteria\":  \n¬†¬†¬†¬†¬†¬†¬† {  \n¬†¬†¬†¬†¬†¬†¬†¬†¬† \"SeriesDescription\": \"SAG FSPGR 3D .9X.9X.9\",  \n¬†¬†¬†¬†¬†¬†¬†¬†¬† \"SeriesNumber\": \"13\"¬†¬†¬†¬†¬†¬†¬† }  \n¬†¬†¬† },  \n¬†¬†¬† {  \n¬†¬†¬†¬†¬† \"datatype\": \"func\",  \n¬†¬†¬†¬†¬† \"suffix\": \"bold\",  \n¬†¬†¬†¬†¬† \"custom_entities\": \"ses-eegfmri_task-handstim\",  \n¬†¬†¬†¬†¬† \"criteria\":  \n¬†¬†¬†¬†¬†¬†¬† {  \n¬†¬†¬†¬†¬†¬†¬†¬†¬† \"SeriesDescription\": \"fMRI Hand Stim\",  \n¬†¬†¬†¬†¬†¬†¬†¬†¬† \"SeriesNumber\": \"9\"¬†¬†¬†¬†¬†¬†¬† }  \n¬†¬†¬† },  \n¬†¬†¬† {  \n¬†¬†¬†¬†¬† \"datatype\": \"func\",  \n¬†¬†¬†¬†¬† \"suffix\": \"bold\",  \n¬†¬†¬†¬†¬† \"custom_entities\": \"ses-eegfmri_task-rest\",  \n¬†¬†¬†¬†¬† \"criteria\":  \n¬†¬†¬†¬†¬†¬†¬† {  \n¬†¬†¬†¬†¬†¬†¬†¬†¬† \"SeriesDescription\": \"fMRI Resting State\",  \n¬†¬†¬†¬†¬†¬†¬†¬†¬† \"SeriesNumber\": \"3\"¬†¬†¬†¬†¬†¬†¬† },  \n¬†¬†¬†¬†¬† \"sidecar_changes\": {  \n¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬† \"SeriesDescription\": \"fMRI Resting State Eyes Closed\"¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬† }  \n¬†¬†¬† },  \n¬†¬†¬† {  \n¬†¬†¬†¬†¬† \"datatype\": \"func\",  \n¬†¬†¬†¬†¬† \"suffix\": \"bold\",  \n¬†¬†¬†¬†¬† \"custom_entities\": \"ses-eegfmri_task-rest\",  \n¬†¬†¬†¬†¬† \"criteria\":  \n¬†¬†¬†¬†¬†¬†¬† {  \n¬†¬†¬†¬†¬†¬†¬†¬†¬† \"SeriesDescription\": \"fMRI Resting State\",  \n¬†¬†¬†¬†¬†¬†¬†¬†¬† \"SeriesNumber\": \"4\"¬†¬†¬†¬†¬†¬†¬† },  \n¬†¬†¬†¬†¬† \"sidecar_changes\": {  \n¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬† \"SeriesDescription\": \"fMRI Resting State Eyes Closed\"¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬† }  \n¬†¬†¬† },  \n¬†¬†¬† {  \n¬†¬†¬†¬†¬† \"datatype\": \"func\",  \n¬†¬†¬†¬†¬† \"suffix\": \"bold\",  \n¬†¬†¬†¬†¬† \"custom_entities\": \"ses-eegfmri_task-rest\",  \n¬†¬†¬†¬†¬† \"criteria\":  \n¬†¬†¬†¬†¬†¬†¬† {  \n¬†¬†¬†¬†¬†¬†¬†¬†¬† \"SeriesDescription\": \"fMRI Resting State\",  \n¬†¬†¬†¬†¬†¬†¬†¬†¬† \"SeriesNumber\": \"5\"¬†¬†¬†¬†¬†¬†¬† },  \n¬†¬†¬†¬†¬† \"sidecar_changes\": {  \n¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬† \"SeriesDescription\": \"fMRI Resting State Eyes Closed\"¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬† }  \n¬†¬†¬† },  \n¬†¬†¬† {  \n¬†¬†¬†¬†¬† \"datatype\": \"func\",  \n¬†¬†¬†¬†¬† \"suffix\": \"bold\",  \n¬†¬†¬†¬†¬† \"custom_entities\": \"ses-eegfmri_task-rest\",  \n¬†¬†¬†¬†¬† \"criteria\":  \n¬†¬†¬†¬†¬†¬†¬† {  \n¬†¬†¬†¬†¬†¬†¬†¬†¬† \"SeriesDescription\": \"fMRI Resting State\",  \n¬†¬†¬†¬†¬†¬†¬†¬†¬† \"SeriesNumber\": \"6\"¬†¬†¬†¬†¬†¬†¬† },  \n¬†¬†¬†¬†¬† \"sidecar_changes\": {  \n¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬† \"SeriesDescription\": \"fMRI Resting State Eyes Closed\"¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬† }  \n¬†¬†¬† },  \n¬†¬†¬† {  \n¬†¬†¬†¬†¬† \"datatype\": \"func\",  \n¬†¬†¬†¬†¬† \"suffix\": \"bold\",  \n¬†¬†¬†¬†¬† \"custom_entities\": \"ses-eegfmri_task-rest\",  \n¬†¬†¬†¬†¬† \"criteria\":  \n¬†¬†¬†¬†¬†¬†¬† {  \n¬†¬†¬†¬†¬†¬†¬†¬†¬† \"SeriesDescription\": \"fMRI Resting State\",  \n¬†¬†¬†¬†¬†¬†¬†¬†¬† \"SeriesNumber\": \"7\"¬†¬†¬†¬†¬†¬†¬† },  \n¬†¬†¬†¬†¬† \"sidecar_changes\":  \n¬†¬†¬†¬†¬†¬†¬† {  \n¬†¬†¬†¬†¬†¬†¬†¬†¬† \"SeriesDescription\": \"fMRI Resting State Eyes Closed\"¬†¬†¬†¬†¬†¬†¬† }  \n¬†¬†¬† },  \n¬†¬†¬† {  \n¬†¬†¬†¬†¬† \"datatype\": \"func\",  \n¬†¬†¬†¬†¬† \"suffix\": \"bold\",  \n¬†¬†¬†¬†¬† \"custom_entities\": \"ses-eegfmri_task-rest\",  \n¬†¬†¬†¬†¬† \"criteria\":  \n¬†¬†¬†¬†¬†¬†¬† {  \n¬†¬†¬†¬†¬†¬†¬†¬†¬† \"SeriesDescription\": \"fMRI Resting State\",  \n¬†¬†¬†¬†¬†¬†¬†¬†¬† \"SeriesNumber\": \"10\"¬†¬†¬†¬†¬†¬†¬† },  \n¬†¬†¬†¬†¬† \"sidecar_changes\": {  \n¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬† \"SeriesDescription\": \"fMRI Resting State Eyes Closed\"¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬† }  \n¬†¬†¬† },  \n¬†¬†¬† {  \n¬†¬†¬†¬†¬† \"datatype\": \"func\",  \n¬†¬†¬†¬†¬† \"suffix\": \"bold\",  \n¬†¬†¬†¬†¬† \"custom_entities\": \"ses-eegfmri_task-rest\",  \n¬†¬†¬†¬†¬† \"criteria\":  \n¬†¬†¬†¬†¬† {  \n¬†¬†¬†¬†¬†¬†¬† \"SeriesDescription\": \"fMRI Resting State\",  \n¬†¬†¬†¬†¬†¬†¬† \"SeriesNumber\": \"11\"¬†¬†¬†¬†¬† },  \n¬†¬†¬†¬†¬† \"sidecar_changes\": {  \n¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬† \"SeriesDescription\": \"fMRI Resting State Eyes Closed\"¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬† }  \n¬†¬†¬† },  \n¬†¬†¬† {  \n¬†¬†¬†¬†¬† \"datatype\": \"func\",  \n¬†¬†¬†¬†¬† \"suffix\": \"bold\",  \n¬†¬†¬†¬†¬† \"custom_entities\": \"ses-eegfmri_task-rest\",  \n¬†¬†¬†¬†¬† \"criteria\":  \n¬†¬†¬†¬†¬†¬†¬† {  \n¬†¬†¬†¬†¬†¬†¬†¬†¬† \"SeriesDescription\": \"fMRI Resting State\",  \n¬†¬†¬†¬†¬†¬†¬†¬†¬† \"SeriesNumber\": \"12\"¬†¬†¬†¬†¬†¬†¬† },  \n¬†¬†¬†¬†¬† \"sidecar_changes\": {  \n¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬† \"SeriesDescription\": \"fMRI Resting State Eyes Closed\"¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬† }  \n¬†¬†¬† }  \n¬† ]  \n}\nOnce you are done, you can run dcm2bids.\ndcm2bids -c code/dcm2bids_config.json -p BHBMEG&lt;subject_id&gt; -d\nsourcedata/mri/ --auto_extract_entities\nCopy the contents of the code¬†directory from a previous eeg-fmri subject to the¬†BHBMEG&lt;subject_id&gt;¬†folder except for the dcm2bids_config.json file you created. Change the information in¬†fmriprep_command.py,¬†convert_mff_to_bids.py, and¬†RemoveBallistocardiogram.mlx¬†to fit your data.\nCreate a folder called¬†mne¬†in the¬†derivatives¬†folder.\nOnce the creation of the BIDS data folder is done, you should have something that looks like:\nBHBMEG004\n‚îú‚îÄ‚îÄ CHANGES\n‚îú‚îÄ‚îÄ README\n‚îú‚îÄ‚îÄ code\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ B3801539-D436-4BC0-81D9-6F9A82244022 (1).pdf\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ Channels4Rodriguez2016\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ RemoveBallistocardiogram.mlx\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ acpc_align.sh\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ bounded line-peg\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ convert_mff_to_bids.py\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ dcm2bids_config.json\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ fmriprep_command.sh\n‚îÇ¬†¬† ‚îî‚îÄ‚îÄ gradient_removal.m\n‚îú‚îÄ‚îÄ dataset_description.json\n‚îú‚îÄ‚îÄ derivatives\n‚îú‚îÄ‚îÄ participants.json\n‚îú‚îÄ‚îÄ participants.tsv\n‚îú‚îÄ‚îÄ sourcedata\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ mri\n‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ BHBEP214A\n‚îÇ¬†¬† ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îî‚îÄ‚îÄ 3\n‚îÇ¬†¬† ‚îÇ¬†¬† ‚îî‚îÄ‚îÄ BHBMEG004B\n‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 10\n‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 11\n‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 12\n‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 13\n‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 3\n‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 4\n‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 5\n‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 6\n‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 7\n‚îÇ¬†¬† ‚îÇ¬†¬† ‚îî‚îÄ‚îÄ 9\n‚îÇ¬†¬† ‚îî‚îÄ‚îÄ tmp_dcm2bids\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ helper\n‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 003\\_.\\_RESEARCH\\_-\\_BHBEP_20190314111207.json\n‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 003\\_.\\_RESEARCH\\_-\\_BHBEP_20190314111207.nii.gz\n‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 003\\_.\\_RESEARCH\\_-\\_BHBMEG_20190507142627.json\n‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 003\\_.\\_RESEARCH\\_\\_BHBMEG_20190507142627.nii.gz\n‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 004\\_.\\_RESEARCH\\_-\\_BHBMEG_20190507142627.json\n‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 004\\_.\\_RESEARCH\\_-\\_BHBMEG_20190507142627.nii.gz\n‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 005\\_.\\_RESEARCH\\_-\\_BHBMEG_20190507142627.json\n‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 005\\_.\\_RESEARCH\\_-\\_BHBMEG_20190507142627.nii.gz\n‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 006\\_.\\_RESEARCH\\_-\\_BHBMEG_20190507142627.json\n‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 006\\_.\\_RESEARCH\\_-\\_BHBMEG_20190507142627.nii.gz\n‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 006\\_.\\_RESEARCH\\_-\\_BHBMEG_20190507142627.nii.gz\n‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 007\\_.\\_RESEARCH\\_-\\_BHBMEG_20190507142627.json\n‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 007\\_.\\_RESEARCH\\_-\\_BHBMEG_20190507142627.nii.gz\n‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 009\\_.\\_RESEARCH\\_-\\_BHBMEG_20190507142627.json\n‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 009\\_.\\_RESEARCH\\_-\\_BHBMEG_20190507142627.nii.gz\n‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 010\\_.\\_RESEARCH\\_-\\_BHBMEG_20190507142627.json\n‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 010\\_.\\_RESEARCH\\_-\\_BHBMEG_20190507142627.nii.gz\n‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 011\\_.\\_RESEARCH\\_-\\_BHBMEG_20190507142627.json\n‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 011\\_.\\_RESEARCH\\_-\\_BHBMEG_20190507142627.nii.gz\n‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 012\\_.\\_RESEARCH\\_-\\_BHBMEG_20190507142627.json\n‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 012\\_.\\_RESEARCH\\_-\\_BHBMEG_20190507142627.nii.gz\n‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 013\\_.\\_RESEARCH\\_-\\_BHBMEG_20190507142627.json\n‚îÇ¬†¬† ‚îÇ¬†¬† ‚îî‚îÄ‚îÄ 013\\_.\\_RESEARCH\\_-\\_BHBMEG_20190507142627.nii.gz\n‚îÇ¬†¬† ‚îî‚îÄ‚îÄ log\n‚îÇ¬†¬† ‚îî‚îÄ‚îÄ helper_20240109-144412.log\n‚îú‚îÄ‚îÄ sub-BHBMEG004\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ anat\n‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ sub-BHBMEG004_ses-brainmap_T1W.json\n‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ sub-BHBMEG004_ses-brainmap_T1W.nii.gz\n‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ sub-BHBMEG004_ses-eegfmri_T1W.json\n‚îÇ¬†¬† ‚îÇ¬†¬† ‚îî‚îÄ‚îÄ sub-BHBMEG004_ses-eegfmri_T1W.nii.gz\n‚îÇ¬†¬† ‚îî‚îÄ‚îÄ func\\\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ sub-BHBMEG004_ses-eegfmri_task-handstim_bold.json\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ sub-BHBMEG004_ses-eegfmri_task-handstim_bold.nii.gz\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ sub-BHBMEG004_ses-eegfmri_task-rest_run-01_bold.json\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ sub-BHBMEG004_ses-eegfmri_task-rest_run-01_bold.nii.gz\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ sub-BHBMEG004_ses-eegfmri_task-rest_run-02_bold.json\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ sub-BHBMEG004_ses-eegfmri_task-rest_run-02_bold.nii.gz\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ sub-BHBMEG004_ses-eegfmri_task-rest_run-03_bold.json\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ sub-BHBMEG004_ses-eegfmri_task-rest_run-03_bold.nii.gz\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ sub-BHBMEG004_ses-eegfmri_task-rest_run-04_bold.json\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ sub-BHBMEG004_ses-eegfmri_task-rest_run-04_bold.nii.gz\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ sub-BHBMEG004_ses-eegfmri_task-rest_run-05_bold.json\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ sub-BHBMEG004_ses-eegfmri_task-rest_run-05_bold.nii.gz\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ sub-BHBMEG004_ses-eegfmri_task-rest_run-06_bold.json\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ sub-BHBMEG004_ses-eegfmri_task-rest_run-06_bold.nii.gz\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ sub-BHBMEG004_ses-eegfmri_task-rest_run-07_bold.json\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ sub-BHBMEG004_ses-eegfmri_task-rest_run-07_bold.nii.gz\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ sub-BHBMEG004_ses-eegfmri_task-rest_run-08_bold.json\n‚îÇ¬†¬† ‚îî‚îÄ‚îÄ sub-BHBMEG004_ses-eegfmri_task-rest_run-08_bold.nii.gz\n‚îî‚îÄ‚îÄ tmp_dcm2bids\n¬†¬† ‚îú‚îÄ‚îÄ log\n¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ scaffold_20240109-142635.log\n¬†¬† ‚îÇ¬†¬† ‚îî‚îÄ‚îÄ sub-BHBMEG004_20240109-180638.log\n¬†¬† ‚îî‚îÄ‚îÄ sub-BHBMEG004\nDeactivate the dcm2bids environment in Terminal.\nconda deactivate\n\n\n\nFor the T1 scan(s) for both the BHBEP and BHBMEG sessions, get the freesurfer surfaces and inflated spheres using recon-all. We will need these to align the EEG data with the MRI data. Include the T1 from the brain mapping session if there is one.\nmkdir BIDS/BHBMEG&lt;subject_id&gt;/derivatives/freesurfer\n\nrecon-all -subject sub-BHBMEG\\&lt;subject_id\\&gt; -I \\&lt;path to anat\nfolder\\&gt;/sub-BHBMEG\\&lt;subject_id\\&gt;\\_ses-eegfmri_T1W.nii.gz -i\nsub-BHBMEG\\&lt;subject_id\\&gt;\\_ses-brainmap_T1W.nii.gz -sd \\&lt;path to BIDS\nfolder\\&gt;/BHBMEG\\&lt;subject_id\\&gt;/derivatives/freesurfer -all\nBe sure to record the¬†freesurfer¬†subject as¬†sub-BHBMEG&lt;id_number&gt; in the derivatives/freesurfer folder. Use the instructions at ¬†https://surfer.nmr.mgh.harvard.edu/fswiki/recon-all¬†if you need help setting this up.\n\n\n\nInstall MNE if you haven‚Äôt done so already (https://mne.tools/stable/install/manual_install.html#manual-install).\nconda install --channel=conda-forge --name=base conda-libmamba-solver\nconda create --solver=libmamba --override-channels\n--channel=conda-forge --name=mne mne\nIf you don't already have them, also install¬†docker (https://docs.docker.com/desktop/install/mac-install/) and add the¬†fmriprep¬†command to your anaconda installation (https://www.anaconda.com/download) using:\nconda activate mne\npip install fmriprep-docker\nconda deactivate\nThen at the command line enter:\nconda activate mne\n\ncd &lt;BIDS_root&gt;code\nzsh fmriprep_command.sh\nconda deactivate\nThis will preprocess the fMRI data in your¬†BHBMEG&lt;subject_id&gt;¬†folder. Be sure to check the quality assurance document that gets outputted in the¬†derivatives/fmriprep¬†folder. If necessary, adjust¬†fmriprep_command.sh¬†and rerun.\n\n\n\n\nMake a directory called¬†eeg¬†in the sourcedata folder. Copy all the EEG data files from NetStation in¬†.mff¬†format into the¬†sourcedata/eeg¬†folder.\nOpen Spyder from the command line in Terminal.\nSpyder\nChange Spyder's Python interpreter to that in the MNE Environment. Click on the wrench in the toolbar. When the dialogue box opens, select Python Interpreter in the left column. Select the mne python interpreter in the list of the python interpreters on the right. It should have your anaconda3 install in the python interpreter name. Mine is:\n![[Pasted image 20240213120910.png]]\nClick OK.\nOpen the¬†convert_mff_to_bids.py¬†script. It is in the¬†code¬†directory in your subject‚Äôs BIDS directory.\nUpdate¬†convert_mff_to_bids.py¬†to list the EEG files from NetStation if you haven't already done so. Enter the filenames for each file. There will be somewhere between 1 and the number of MR resting state + the hand stim task runs of EEG data.\nIf the number of EEG runs is equal to the number of MR runs, use the first and last data points as the EEG run start and end (default). If the number of EEG runs is less than the number of MR runs, use the notes taken during acquisition to determine which MR runs are included in each EEG run. Once the distribution of MR runs in each EEG file is determined, open the data in your favourite viewer and mark timepoints between runs (this is the ‚Äúquiet‚Äù periods between MR gradient artifacts. Pick a point about midway between the 2 MR runs and note the value in milliseconds. This will be the end point of your EEG run. Add one millisecond and this will be the beginning of the next MR run.\nOnce you have determined the break point values, run the script.\n\n\nThe first thing to be created is the¬†bem¬†folder in the¬†derivatives/freesurfer/sub-BHBMEG&lt;subject_id&gt;¬†folder. The make_bem flag in convert_mff_to_bids.py needs to be set to True.\nmake_bem = True\nThe¬†freesurfer¬†recon-all run above needs to have completed before doing this. This will create the head and scalp surfaces from your¬†freesurfer¬†output.\n\n\n\nIf you don't already have a .trans¬†file in your¬†derivatives/mne¬†folder, we will now create one. When you run convert_mff_to_bids.py, the graphical user interface for¬†PyVista will open. Be patient with¬†PyVista, it takes a very long time to load. You will see the outer skin surface with 3 marks. This is the program's best guess at where the nasion and preauricular points are on the scalp surface.\n\nIf the points don't align with the marks from the EEG net, realign the points to correspond to where the EEG net was placed.\nOn the left side, if the Lock fiducials checkbox is checked, uncheck it. Underneath you have LPA. This is the left preauricular point. Click on the radio button beside LPA.\n\nMove the red fiducial marker to the circleish place in front of the ear corresponding to the placement of the preauricular point from the EEG net.\n\nThis gives the relationship between the EEG net placement and the underlying MR anatomy.\nNow click on the radio button beside Nasion. Move the green fiducial marker to where the EEG net is sitting on the face.\n\nRepeat for the right preauricular point (RPA).\n\n\n\n\nFill in the MR runs contained in each EEG run. The script will ask you for this information. Remember to include the opening and closing square brackets (e.g., [3, 4, 5, ‚Ä¶]) for the list of MR runs contained in the EEG run. The MR run will not have a value of less than 3 because of the calibration scans preceding the scan.\nEnter the start and end points of each MR run in the EEG data when asked to do so if more than one MR run is in an EEG run (i.e., n_mr_runs &gt; n_eeg_runs) in the¬†convert_mff_to_bids.py¬†script.\nThis script will save a¬†EEGLAB¬†.set¬†file in the derivatives/mne¬†directory for the eeg data corresponding to each MR run labeled with the run numbers in the¬†BIDS directory.\n\n\n\nDownload¬†EEGLAB¬†from¬†https://sccn.ucsd.edu/eeglab/download.php. Follow the install instructions. Add the¬†EEGLAB¬†path to your¬†Matlab¬†path.\nIn the Matlab command window, type\neeglab\nThis will open the following dialogue box:\n\nIf you haven't already done so, add the fMRIb MRI Tools. In the main EEGLAB window, go to¬†File &gt; Manage EEGLAB extensions. This will open another dialogue box:\n\nIn the search bar, type in¬†MRI.\n\nSelect the extension labelled¬†fMRIb¬†(download the latest stable version).\n\nClick¬†Install/Update.\nClose the main EEGLAB window.\n\n\n\n\nChange the¬†Matlab¬†directory to the root of your BIDS folder structure for your subject. In Matlab 2022a, this is:\ncd &lt;path to BIDS root&gt;\nNote that you must use Matlab 2018b or above with the signal processing and the stats toolboxes. If you don‚Äôt have the toolboxes, contact BCCHR IT.\nYou want to open the .set file for the EEG-MRI run stored in your¬†derivatives/mne/sub-&lt;subject_id&gt;¬†folder.\nOpen the main¬†EEGLAB window.\neeglab\nClick¬†File &gt; Load existing dataset. Navigate to the¬†derivatives/mne/sub-&lt;subject_id&gt;¬†folder. Select the .set file for the EEG-fMRI run you want to process.\n\nNow we need to get the TRs. They have been saved as an extra channel. They should be stored in channel 258, but we want to check first. Go to¬†Plot &gt; Channel data (scroll).\n\nHowever, the display is too busy. Go to¬†Settings &gt; Number of channels¬†to display. In the pop-up dialogue box, put a number between 10 and 25, depending upon the size of your monitor and what you feel more comfortable with. Click¬†Ok. Scroll down using the bar on the left. Check that TR is listed as channel 258.\n\nThe noise in the data is the gradient artifact.\nNow that we have verified that the TRs are stored in channel 258 click¬†CANCEL.\nNow we need the TRs as events and not as a channel. Go to¬†File &gt; Import event data &gt; From data channel.\n\nEnter 258 for¬†Event channel(s). Be sure to unclick¬†Delete event channel(s)¬†and¬†Delete old events¬†if any. Your display should look like the above dialogue box. Click¬†Ok.\nIn the original dialogue box, go to¬†Tools &gt; FMRIB Tools &gt; FASTR: Remove MRI gradient artifacts. Again, this will open another dialogue box.\n\nThe TRs come one for every volume. Change Artifact timing event to Volume/Section. Make sure that the Artifact timing event reads either TR or the channel that you entered for the TR signal from the previous step (usually chan258, but check to be sure). Check the box beside Adaptive Noise Cancellation.\n\nPress Ok.\nRepeat for all other functional MR runs.\n\n\nThis algorithm uses Cameron Rodriguez's (2016) method to derive the cardiac signal from selected channels in the EEG signal. Please see¬†Rodriguez (2016)¬†for more details.\nIn¬†Matlab¬†open the¬†RemoveBallistocardiogram.mlx¬†file from the¬†code¬†directory in your subject's root BIDS directory. Note that you need to be using¬†Matlab 2022a or above¬†and have the¬†signal processing toolbox¬†installed. If you don't have these, contact BCCHR/UBC IT to find out how to get these for your account.\nOnce¬†RemoveBallistocardiogram.mlx¬†is open, change the data in boxes 1 through 3. In the first box, change¬†e¬†to the number of MR runs of resting state data that you have (e.g., e = 7 MR runs). Next, change the names of the output files in BIDS format to fit your data. You should only have to change the¬†sub-BHBMEG&lt;subject_id&gt;**¬†part and change the number of successful MR runs. This will put¬†.txt¬†files with the SPPeaks of the cardiac signal.\n\nNext, we need to add the path to our gradient removed eeg data in the ./derivatives/mne folder of the root BIDS directory.\n\nOnce you have your directory path set, fill in the names of each of your gradient cleaned EEG runs.\n\nNow in¬†Matlab\\'s LIVE EDITOR¬†window, press the¬†run¬†button (green right pointing arrowhead). The script will loop through your EEG runs for each MR run and output a .txt file for each run. These are the SPPeaks from the cardiac symbol.\n\n\n\n\nNow that you have the files with the SP Peaks, you are ready to remove the ballistocardiogram from your EEG signal. In¬†Matlab, open¬†EEGLAB:\neeglab\nIn the EEGLAB main window, open the first of your gradient cleaned EEG .set files (i.e.,¬†sub-BHBMEG&lt;subject_id&gt;_ses-eegfmri_task-rest_run-&lt;run number&gt;_desc-gr_eeg.set) using¬†File \\&gt; Load existing dataset. Once opened, we need to import the .txt file with the events corresponding to the SP Peaks in that particular run. To do that, we go to File &gt; Import event info &gt; From MATLAB array or ASCII file. This will open the following dialogue box:\n\nSelect Browse and select the¬†BHBMEG&lt;subject_id&gt;_ses-eegfmri_task-rest_run-&lt;run number&gt;_desc-gr-sppeak_eeg.txt¬†file corresponding to the EEG run you loaded previously. Add the words latency type to the Input field (column) names box, change the Number of file header lines to 1, the Time unit (sec) to NaN and uncheck the **Auto adjust new events sampling rate. Your dialogue box should look like the following:\n\nPress Ok.\nCheck that the file loaded in the main EEGLAB window. The number of events should increase by at least approximately six hundred to fifteen hundred (give or take a bit to adjust for changes and individual differences in heart rate).\n\nNow we need to go to Tools &gt; fMRIb Tools &gt; Remove pulse artifacts. This will open the following dialogue box:\n\nMake sure QRS/Heartbeat Event is sppeak. Select Optimal Basis Set. Leave the default value of 3 in the Number of PCs to use. Press Ok.\nYou will see the progress in the Matlab Console window.\n\nOnce completed, be sure to save the new file as¬†BHBMEG&lt;subject_id&gt;_ses-eegfmri_task-rest_run-&lt;run number&gt;_desc-gr-sppeak-qrs_eeg.set. Overwrite the gradient cleaned version in the main EEGLAB window.\n\nCheck the data by opening the file in the EEGLAB viewer. Go to Plot &gt; Channel data (scroll. In the plot window, select Display &gt; Remove DC offset and Settings &gt; Number of channels to display. Set the number in the new dialogue box to somewhere between 10 and 20 channels depending upon your preference.\n\nExport the data in¬†.edf¬†format so that the epileptologist can view the file in¬†Natus¬†(the proprietary system used in the EEG department) or NetStation. In the main EEGLAB¬†window, select File \\&gt; Export \\&gt; Data¬†to EDF/BDF/GDF file. If you are asked to install the Biosig extension, press¬†Yes. Save the file as¬†sub-BHBMEG\\&lt;subject_id\\&gt;\\_ses-eegfmri_task-rest_run-\\&lt;run number\\&gt;\\_desc-gr-sppeak-qrs_eeg.edf. Make sure to use the .edf file extension. This will open a dialogue box:\n\nHighlight EDF and press Ok. This will write the EDF file to disk.\nRepeat the Remove Ballistocardiogram using FIMRIB EEGLAB Plugin steps for all other MR/EEG gradient cleaned files (one corresponding to each MR run).\n\n\n\nOnce you are finished cleaning and checking the EEG data, notify the epileptologist who made the referral for spike reading in the EEG file. Ask if they would prefer to read the spikes in¬†Natus¬†or¬†Netstation and prepare the software accordingly. If using Natus, you will need to make arrangements with the EEG department to bring the files over and have them installed on their¬†Natus¬†system. If loading in Natus, be sure to bring the patient‚Äôs name and date of birth along with the anonymized¬†.edf¬†files as the records will become part of the EEG department‚Äôs records for that patient/subject. If you don‚Äôt want the results to become part of the patient‚Äôs medical record, make sure the epileptologist reads the data in NetStation in the Brain Mapping Lab.\nOnce the epileptologist has read the spikes in each run, export the events from either¬†Netstation¬†or¬†Natus¬†for each run to a¬†.txt¬†(ASCII file). It is these events that will be used to\n\nrun an¬†event-related design¬†for your fMRI runs in¬†FSL FEAT, and\ncreate epochs and run a¬†beamformer¬†in¬†MNE.\n\nReferences\nRodriguez, C. (2016).¬†Improvements to Simultaneous Electroencepalography-Functional Magnetic Resonance Imaging and Electroencepalographic Source Localization. Dissertation.¬†https://escholarship.org/uc/item/3gg3z2q6",
    "crumbs": [
      "Home",
      "MRI Methods",
      "EEG-fMRI",
      "EEG-fMRI Data Cleaning & Forward Solution"
    ]
  },
  {
    "objectID": "mrimethods/eeg-fmri/gradient-removal.html#high-level-overview-of-eeg-fmri-artifact-cleaning-procedure",
    "href": "mrimethods/eeg-fmri/gradient-removal.html#high-level-overview-of-eeg-fmri-artifact-cleaning-procedure",
    "title": "EEG-fMRI Data Cleaning & Forward Solution",
    "section": "",
    "text": "The procedure for cleaning MR and BCG artifacts from EEG data can be summarized in three main steps:\n\nArtifact Identification: Detecting and marking the artifacts within the EEG data that stem from MR and BCG sources.\nArtifact Removal: Implementing algorithms and techniques designed to exclude or minimize the intrusion of identified artifacts.\nData Validation: Assessing the cleaned EEG data to confirm the efficacy of artifact removal and ensuring the integrity of the signal for further analysis.\n\nThis high-level overview provides a foundational understanding of the procedural steps involved without delving into complex technicalities.",
    "crumbs": [
      "Home",
      "MRI Methods",
      "EEG-fMRI",
      "EEG-fMRI Data Cleaning & Forward Solution"
    ]
  },
  {
    "objectID": "mrimethods/eeg-fmri/gradient-removal.html#data-preparation",
    "href": "mrimethods/eeg-fmri/gradient-removal.html#data-preparation",
    "title": "EEG-fMRI Data Cleaning & Forward Solution",
    "section": "",
    "text": "Use the subject id from the MR scanner EEG-fMRI session.\ncd BHBMEG&lt;subject_id&gt;\n\n\n\nPut the MRI data in BIDS format using your favourite BIDS conversion tool. I recommend dcm2bids. You can find more information at https://unfmontreal.github.io/Dcm2Bids/3.1.1/. Be sure that the subject is the root BIDS directory (i.e., only one subject in the BIDS directory) to keep the analysis as a N = 1 study.\nInstall anaconda if you haven‚Äôt already done so. Go to https://www.anaconda.com/download. Follow the install directions for your workstation and operating system.\nOpen a Terminal window. Check your Python version. At the command prompt, type\nwhich python\nIf the command should return a path with anaconda3 in it. For example,\n/Users/lj/anaconda3/bin/python\nCreate a python environment for dcm2bids. In a text file called environment.yml copy the following:\nname: dcm2bids\\\nchannels:\\\n- conda-forge\\\ndependencies:\\\n- python\\&gt;=3.7\\\n- dcm2niix\\\n- dcm2bids\nand in Terminal create the environment:\nconda env create --file environment.yml*\nActivate your new python environment. By running\nconda activate dcm2bids\nTest your dcm2bids installation.\ndcm2bids *\\--help*\nYou should get the help file for dcm2bids:\nusage: dcm2bids [-h] -d DICOM_DIR [DICOM_DIR ...] -p PARTICIPANT [-s SESSION]  \n¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬† -c CONFIG [-o OUTPUT_DIR] [_--auto_extract_entities]_¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬† [_--bids_validate] [--force_dcm2bids] [--skip_dcm2niix]_¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬† [_--clobber] [-l {DEBUG,INFO,WARNING,ERROR,CRITICAL}] [-v]_Reorganising NIfTI files from dcm2niix into the Brain Imaging Data Structure  \n  \noptions:  \n¬† -h, _--help¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬† show this help message and exit_¬† -d DICOM_DIR [DICOM_DIR ...], _--dicom_dir DICOM_DIR [DICOM_DIR ...]_¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬† DICOM directory(ies) or archive(s) (tar, tar.bz2, tar.gz or zip).  \n¬† -p PARTICIPANT, _--participant PARTICIPANT_¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬† Participant ID.  \n¬† -s SESSION, _--session SESSION_¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬† Session ID. []  \n¬† -c CONFIG, _--config CONFIG_¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬† JSON configuration file (see example/config.json).  \n¬† -o OUTPUT_DIR, _--output_dir OUTPUT_DIR_¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬† Output BIDS directory. [/Users/lj]¬† _--auto_extract_entities_¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬† If set, it will automatically try to extract entityinformation [task, dir, echo] based on the suffix and datatype. [False]¬† _--bids_validate¬†¬†¬†¬†¬†¬† If set, once your conversion is done it will check if your output folder is BIDS valid. [False]_¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬† bids-validator needs to be installed check: https://github.com/bids-standard/bids-validator_#quickstart_¬† _--force_dcm2bids¬†¬†¬†¬†¬† Overwrite previous temporary dcm2bids output if it exists._¬† _--skip_dcm2niix¬†¬†¬†¬†¬†¬† Skip dcm2niix conversion. Option -d should contains NIFTI and json files._¬† _--clobber¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬† Overwrite output if it exists._¬† -l {DEBUG,INFO,WARNING,ERROR,CRITICAL}, _--log_level {DEBUG,INFO,WARNING,ERROR,CRITICAL}_¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬† Set logging level to the console. [INFO]  \n¬† -v, _--version¬†¬†¬†¬†¬†¬†¬†¬† Report dcm2bids version and the BIDS version._Documentation at https://unfmontreal.github.io/Dcm2Bids/\nMake a directory for your BIDS root directory:\nmkdir BIDS\\\ncd BIDS\nCreate the scaffold for your BIDS root directory:\ndcm2bids_scaffold -o BHBMEG&lt;subject_id\\&gt;\ncd BHBMEG&lt;subject_id&gt;\nDownload your MRI data from XNAT for BHBMEG&lt;subject_id&gt;.\nPut the MRI data in the sourcedata folder created by the scaffold.\nunzip \\&lt;xnat-username\\&gt;-\\&lt;download-date\\&gt;\\_\\&lt;download-time\\&gt;.zip -d\nsourcedata/\nFor example,\nunzip lwilliams-20240109_134304.zip -d sourcedata/\nChange the folder name to mri.\nmv ./sourcedata/\\&lt;xnat-username\\&gt;-\\&lt;download-date\\&gt;\\_\\&lt;download-time\\&gt;\nmri\nFor example,\nmv ./sourcedata/ lwilliams-20240109_134304 mri\nMove any additional MRI sessions into the mri folder (e.g., the structural scans from a corresponding BHBEP session).\nCreate a new .config file in the code folder of your subject‚Äôs BIDS folder. You can use any code editor, but here we will use nano.\ncd \\&lt;path to subject's BIDS directory\\&gt;\nnano code/dcm2bids_config.json\nIn the dcm2bids_config.json file in the editor window, add the following:\n{\n\"descriptions\": [ ]\n}\nChange directory back to the sourcedata/mri folder:\ncd &lt;path to BHBMEG&lt;subject_id&gt; directory&gt;/sourcedata/mri\nRun the dcm2bids_helper function:\ndcm2bids_helper -d . \nNote that the period indicates to run dcm2bids_helper function in the current directory. It will create a folder in that directory call tmp_dcm2bids/helper. Here you will find your NIFTI files using the names given by the scanner console. You can check what is in the folder by running ls:\nls tmp_dcm2bids/helper \nFor each scan, there will be 2 files: the NIFTI file and a .json sidecar:\nls tmp/dcm2bids/helper/*\n003\\_.\\_RESEARCH\\_-\\_BHBEP_20190314111207.json\n003\\_.\\_RESEARCH\\_-\\_BHBEP_20190314111207.nii.gz\n003\\_.\\_RESEARCH\\_-\\_BHBMEG_20190507142627.json\n003\\_.\\_RESEARCH\\_\\_BHBMEG_20190507142627.nii.gz\n004\\_.\\_RESEARCH\\_-\\_BHBMEG_20190507142627.json\n004\\_.\\_RESEARCH\\_-\\_BHBMEG_20190507142627.nii.gz\n005\\_.\\_RESEARCH\\_-\\_BHBMEG_20190507142627.json\n005\\_.\\_RESEARCH\\_-\\_BHBMEG_20190507142627.nii.gz\n006\\_.\\_RESEARCH\\_-\\_BHBMEG_20190507142627.json\n006\\_.\\_RESEARCH\\_-\\_BHBMEG_20190507142627.nii.gz\n006\\_.\\_RESEARCH\\_-\\_BHBMEG_20190507142627.nii.gz\n007\\_.\\_RESEARCH\\_-\\_BHBMEG_20190507142627.json\n007\\_.\\_RESEARCH\\_-\\_BHBMEG_20190507142627.nii.gz\n009\\_.\\_RESEARCH\\_-\\_BHBMEG_20190507142627.json\n009\\_.\\_RESEARCH\\_-\\_BHBMEG_20190507142627.nii.gz\n010\\_.\\_RESEARCH\\_-\\_BHBMEG_20190507142627.json\n010\\_.\\_RESEARCH\\_-\\_BHBMEG_20190507142627.nii.gz\n011\\_.\\_RESEARCH\\_-\\_BHBMEG_20190507142627.json\n011\\_.\\_RESEARCH\\_-\\_BHBMEG_20190507142627.nii.gz\n012\\_.\\_RESEARCH\\_-\\_BHBMEG_20190507142627.json\n012\\_.\\_RESEARCH\\_-\\_BHBMEG_20190507142627.nii.gz\n013\\_.\\_RESEARCH\\_-\\_BHBMEG_20190507142627.json\n013\\_.\\_RESEARCH\\_-\\_BHBMEG_20190507142627.nii.gz\nYou will use the information in the sidecar file to put your data into BIDS format.\nTo populate the config file, you need to inspect each of the sidecar files one at a time to make sure there is a unique match for the acquisitions. You can use the ‚ÄúSeriesDescription‚Äù field to help you.\ncat ./sourcedata/mri/tmp_dcm2bids/helper/\nChange directories into the helper folder:\ncd &lt;Path to BHBMEG&lt;subject_id&gt; folder&gt;/sourcedata/mri/tmp_dcm2bids/helper\nFind the Series Description using grep. For example,\ngrep SeriesDescription *.json\nwhich returns the lines:\n003_._RESEARCH_-_BHBEP_20190314111207.json: \"SeriesDescription\": \"SAG MPRAGE PROMO 0.9x0.9x0.9\",\n003_._RESEARCH_-_BHBMEG_20190507142627.json: \"SeriesDescription\": \"fMRI Resting State\",\n004_._RESEARCH_-_BHBMEG_20190507142627.json: \"SeriesDescription\": \"fMRI Resting State\",\n005_._RESEARCH_-_BHBMEG_20190507142627.json: \"SeriesDescription\": \"fMRI Resting State\",\n006_._RESEARCH_-_BHBMEG_20190507142627.json: \"SeriesDescription\": \"fMRI Resting State\",\n007_._RESEARCH_-_BHBMEG_20190507142627.json: \"SeriesDescription\": \"fMRI Resting State\",\n009_._RESEARCH_-_BHBMEG_20190507142627.json: \"SeriesDescription\": \"fMRI Hand Stim\",\n010_._RESEARCH_-_BHBMEG_20190507142627.json: \"SeriesDescription\": \"fMRI Resting State\",\n011_._RESEARCH_-_BHBMEG_20190507142627.json: \"SeriesDescription\": \"fMRI Resting State\",\n012_._RESEARCH_-_BHBMEG_20190507142627.json: \"SeriesDescription\": \"fMRI Resting State\",\n013_._RESEARCH_-_BHBMEG_20190507142627.json: \"SeriesDescription\": \"SAG FSPGR 3D .9X.9X.9\"\nWe can add it to our config file.\n{\n\"descriptions\\\": [\n  {\n    \"datatype\": \"anat\",\n    \"suffix\": \"T1w\",\n    \"custom_entities\": \"ses-brainmap\",\n    \"criteria\": {\n      \"SeriesDescription\": \"SAG MPRAGE PROMO 0.9x0.9x0.9\",\n      \"SeriesNumber\": \"3\"\n      }\n    }\n  ]\n}\nMake sure that the ‚Äúcriteria‚Äù together identify only one MRI sequence. Look at SeriesNumber to differentiate the files. Continue until you have completed this exercise for all runs for all sequences. You should get something that looks like below:\n{  \n¬† \"descriptions\": [  \n¬†¬†¬† {  \n¬†¬†¬†¬†¬† \"datatype\": \"anat\",  \n¬†¬†¬†¬†¬† \"suffix\": \"T1W\",  \n¬†¬†¬†¬†¬† \"custom_entities\": \"ses-brainmap\",  \n¬†¬†¬†¬†¬† \"criteria\":  \n¬†¬†¬†¬†¬†¬†¬† {  \n¬†¬†¬†¬†¬†¬†¬†¬†¬† \"SeriesDescription\": \"SAG MPRAGE PROMO 0.9x0.9x0.9\",  \n¬†¬†¬†¬†¬†¬†¬†¬†¬† \"SeriesNumber\": \"3\"¬†¬†¬†¬†¬†¬†¬† }  \n¬†¬†¬† },  \n¬†¬†¬† {  \n¬†¬†¬†¬†¬† \"datatype\": \"anat\",  \n¬†¬†¬†¬†¬† \"suffix\": \"T1W\",  \n¬†¬†¬†¬†¬† \"custom_entities\": \"ses-eegfmri\",  \n¬†¬†¬†¬†¬† \"criteria\":  \n¬†¬†¬†¬†¬†¬†¬† {  \n¬†¬†¬†¬†¬†¬†¬†¬†¬† \"SeriesDescription\": \"SAG FSPGR 3D .9X.9X.9\",  \n¬†¬†¬†¬†¬†¬†¬†¬†¬† \"SeriesNumber\": \"13\"¬†¬†¬†¬†¬†¬†¬† }  \n¬†¬†¬† },  \n¬†¬†¬† {  \n¬†¬†¬†¬†¬† \"datatype\": \"func\",  \n¬†¬†¬†¬†¬† \"suffix\": \"bold\",  \n¬†¬†¬†¬†¬† \"custom_entities\": \"ses-eegfmri_task-handstim\",  \n¬†¬†¬†¬†¬† \"criteria\":  \n¬†¬†¬†¬†¬†¬†¬† {  \n¬†¬†¬†¬†¬†¬†¬†¬†¬† \"SeriesDescription\": \"fMRI Hand Stim\",  \n¬†¬†¬†¬†¬†¬†¬†¬†¬† \"SeriesNumber\": \"9\"¬†¬†¬†¬†¬†¬†¬† }  \n¬†¬†¬† },  \n¬†¬†¬† {  \n¬†¬†¬†¬†¬† \"datatype\": \"func\",  \n¬†¬†¬†¬†¬† \"suffix\": \"bold\",  \n¬†¬†¬†¬†¬† \"custom_entities\": \"ses-eegfmri_task-rest\",  \n¬†¬†¬†¬†¬† \"criteria\":  \n¬†¬†¬†¬†¬†¬†¬† {  \n¬†¬†¬†¬†¬†¬†¬†¬†¬† \"SeriesDescription\": \"fMRI Resting State\",  \n¬†¬†¬†¬†¬†¬†¬†¬†¬† \"SeriesNumber\": \"3\"¬†¬†¬†¬†¬†¬†¬† },  \n¬†¬†¬†¬†¬† \"sidecar_changes\": {  \n¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬† \"SeriesDescription\": \"fMRI Resting State Eyes Closed\"¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬† }  \n¬†¬†¬† },  \n¬†¬†¬† {  \n¬†¬†¬†¬†¬† \"datatype\": \"func\",  \n¬†¬†¬†¬†¬† \"suffix\": \"bold\",  \n¬†¬†¬†¬†¬† \"custom_entities\": \"ses-eegfmri_task-rest\",  \n¬†¬†¬†¬†¬† \"criteria\":  \n¬†¬†¬†¬†¬†¬†¬† {  \n¬†¬†¬†¬†¬†¬†¬†¬†¬† \"SeriesDescription\": \"fMRI Resting State\",  \n¬†¬†¬†¬†¬†¬†¬†¬†¬† \"SeriesNumber\": \"4\"¬†¬†¬†¬†¬†¬†¬† },  \n¬†¬†¬†¬†¬† \"sidecar_changes\": {  \n¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬† \"SeriesDescription\": \"fMRI Resting State Eyes Closed\"¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬† }  \n¬†¬†¬† },  \n¬†¬†¬† {  \n¬†¬†¬†¬†¬† \"datatype\": \"func\",  \n¬†¬†¬†¬†¬† \"suffix\": \"bold\",  \n¬†¬†¬†¬†¬† \"custom_entities\": \"ses-eegfmri_task-rest\",  \n¬†¬†¬†¬†¬† \"criteria\":  \n¬†¬†¬†¬†¬†¬†¬† {  \n¬†¬†¬†¬†¬†¬†¬†¬†¬† \"SeriesDescription\": \"fMRI Resting State\",  \n¬†¬†¬†¬†¬†¬†¬†¬†¬† \"SeriesNumber\": \"5\"¬†¬†¬†¬†¬†¬†¬† },  \n¬†¬†¬†¬†¬† \"sidecar_changes\": {  \n¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬† \"SeriesDescription\": \"fMRI Resting State Eyes Closed\"¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬† }  \n¬†¬†¬† },  \n¬†¬†¬† {  \n¬†¬†¬†¬†¬† \"datatype\": \"func\",  \n¬†¬†¬†¬†¬† \"suffix\": \"bold\",  \n¬†¬†¬†¬†¬† \"custom_entities\": \"ses-eegfmri_task-rest\",  \n¬†¬†¬†¬†¬† \"criteria\":  \n¬†¬†¬†¬†¬†¬†¬† {  \n¬†¬†¬†¬†¬†¬†¬†¬†¬† \"SeriesDescription\": \"fMRI Resting State\",  \n¬†¬†¬†¬†¬†¬†¬†¬†¬† \"SeriesNumber\": \"6\"¬†¬†¬†¬†¬†¬†¬† },  \n¬†¬†¬†¬†¬† \"sidecar_changes\": {  \n¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬† \"SeriesDescription\": \"fMRI Resting State Eyes Closed\"¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬† }  \n¬†¬†¬† },  \n¬†¬†¬† {  \n¬†¬†¬†¬†¬† \"datatype\": \"func\",  \n¬†¬†¬†¬†¬† \"suffix\": \"bold\",  \n¬†¬†¬†¬†¬† \"custom_entities\": \"ses-eegfmri_task-rest\",  \n¬†¬†¬†¬†¬† \"criteria\":  \n¬†¬†¬†¬†¬†¬†¬† {  \n¬†¬†¬†¬†¬†¬†¬†¬†¬† \"SeriesDescription\": \"fMRI Resting State\",  \n¬†¬†¬†¬†¬†¬†¬†¬†¬† \"SeriesNumber\": \"7\"¬†¬†¬†¬†¬†¬†¬† },  \n¬†¬†¬†¬†¬† \"sidecar_changes\":  \n¬†¬†¬†¬†¬†¬†¬† {  \n¬†¬†¬†¬†¬†¬†¬†¬†¬† \"SeriesDescription\": \"fMRI Resting State Eyes Closed\"¬†¬†¬†¬†¬†¬†¬† }  \n¬†¬†¬† },  \n¬†¬†¬† {  \n¬†¬†¬†¬†¬† \"datatype\": \"func\",  \n¬†¬†¬†¬†¬† \"suffix\": \"bold\",  \n¬†¬†¬†¬†¬† \"custom_entities\": \"ses-eegfmri_task-rest\",  \n¬†¬†¬†¬†¬† \"criteria\":  \n¬†¬†¬†¬†¬†¬†¬† {  \n¬†¬†¬†¬†¬†¬†¬†¬†¬† \"SeriesDescription\": \"fMRI Resting State\",  \n¬†¬†¬†¬†¬†¬†¬†¬†¬† \"SeriesNumber\": \"10\"¬†¬†¬†¬†¬†¬†¬† },  \n¬†¬†¬†¬†¬† \"sidecar_changes\": {  \n¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬† \"SeriesDescription\": \"fMRI Resting State Eyes Closed\"¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬† }  \n¬†¬†¬† },  \n¬†¬†¬† {  \n¬†¬†¬†¬†¬† \"datatype\": \"func\",  \n¬†¬†¬†¬†¬† \"suffix\": \"bold\",  \n¬†¬†¬†¬†¬† \"custom_entities\": \"ses-eegfmri_task-rest\",  \n¬†¬†¬†¬†¬† \"criteria\":  \n¬†¬†¬†¬†¬† {  \n¬†¬†¬†¬†¬†¬†¬† \"SeriesDescription\": \"fMRI Resting State\",  \n¬†¬†¬†¬†¬†¬†¬† \"SeriesNumber\": \"11\"¬†¬†¬†¬†¬† },  \n¬†¬†¬†¬†¬† \"sidecar_changes\": {  \n¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬† \"SeriesDescription\": \"fMRI Resting State Eyes Closed\"¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬† }  \n¬†¬†¬† },  \n¬†¬†¬† {  \n¬†¬†¬†¬†¬† \"datatype\": \"func\",  \n¬†¬†¬†¬†¬† \"suffix\": \"bold\",  \n¬†¬†¬†¬†¬† \"custom_entities\": \"ses-eegfmri_task-rest\",  \n¬†¬†¬†¬†¬† \"criteria\":  \n¬†¬†¬†¬†¬†¬†¬† {  \n¬†¬†¬†¬†¬†¬†¬†¬†¬† \"SeriesDescription\": \"fMRI Resting State\",  \n¬†¬†¬†¬†¬†¬†¬†¬†¬† \"SeriesNumber\": \"12\"¬†¬†¬†¬†¬†¬†¬† },  \n¬†¬†¬†¬†¬† \"sidecar_changes\": {  \n¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬† \"SeriesDescription\": \"fMRI Resting State Eyes Closed\"¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬† }  \n¬†¬†¬† }  \n¬† ]  \n}\nOnce you are done, you can run dcm2bids.\ndcm2bids -c code/dcm2bids_config.json -p BHBMEG&lt;subject_id&gt; -d\nsourcedata/mri/ --auto_extract_entities\nCopy the contents of the code¬†directory from a previous eeg-fmri subject to the¬†BHBMEG&lt;subject_id&gt;¬†folder except for the dcm2bids_config.json file you created. Change the information in¬†fmriprep_command.py,¬†convert_mff_to_bids.py, and¬†RemoveBallistocardiogram.mlx¬†to fit your data.\nCreate a folder called¬†mne¬†in the¬†derivatives¬†folder.\nOnce the creation of the BIDS data folder is done, you should have something that looks like:\nBHBMEG004\n‚îú‚îÄ‚îÄ CHANGES\n‚îú‚îÄ‚îÄ README\n‚îú‚îÄ‚îÄ code\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ B3801539-D436-4BC0-81D9-6F9A82244022 (1).pdf\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ Channels4Rodriguez2016\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ RemoveBallistocardiogram.mlx\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ acpc_align.sh\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ bounded line-peg\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ convert_mff_to_bids.py\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ dcm2bids_config.json\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ fmriprep_command.sh\n‚îÇ¬†¬† ‚îî‚îÄ‚îÄ gradient_removal.m\n‚îú‚îÄ‚îÄ dataset_description.json\n‚îú‚îÄ‚îÄ derivatives\n‚îú‚îÄ‚îÄ participants.json\n‚îú‚îÄ‚îÄ participants.tsv\n‚îú‚îÄ‚îÄ sourcedata\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ mri\n‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ BHBEP214A\n‚îÇ¬†¬† ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îî‚îÄ‚îÄ 3\n‚îÇ¬†¬† ‚îÇ¬†¬† ‚îî‚îÄ‚îÄ BHBMEG004B\n‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 10\n‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 11\n‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 12\n‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 13\n‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 3\n‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 4\n‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 5\n‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 6\n‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 7\n‚îÇ¬†¬† ‚îÇ¬†¬† ‚îî‚îÄ‚îÄ 9\n‚îÇ¬†¬† ‚îî‚îÄ‚îÄ tmp_dcm2bids\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ helper\n‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 003\\_.\\_RESEARCH\\_-\\_BHBEP_20190314111207.json\n‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 003\\_.\\_RESEARCH\\_-\\_BHBEP_20190314111207.nii.gz\n‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 003\\_.\\_RESEARCH\\_-\\_BHBMEG_20190507142627.json\n‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 003\\_.\\_RESEARCH\\_\\_BHBMEG_20190507142627.nii.gz\n‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 004\\_.\\_RESEARCH\\_-\\_BHBMEG_20190507142627.json\n‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 004\\_.\\_RESEARCH\\_-\\_BHBMEG_20190507142627.nii.gz\n‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 005\\_.\\_RESEARCH\\_-\\_BHBMEG_20190507142627.json\n‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 005\\_.\\_RESEARCH\\_-\\_BHBMEG_20190507142627.nii.gz\n‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 006\\_.\\_RESEARCH\\_-\\_BHBMEG_20190507142627.json\n‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 006\\_.\\_RESEARCH\\_-\\_BHBMEG_20190507142627.nii.gz\n‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 006\\_.\\_RESEARCH\\_-\\_BHBMEG_20190507142627.nii.gz\n‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 007\\_.\\_RESEARCH\\_-\\_BHBMEG_20190507142627.json\n‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 007\\_.\\_RESEARCH\\_-\\_BHBMEG_20190507142627.nii.gz\n‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 009\\_.\\_RESEARCH\\_-\\_BHBMEG_20190507142627.json\n‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 009\\_.\\_RESEARCH\\_-\\_BHBMEG_20190507142627.nii.gz\n‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 010\\_.\\_RESEARCH\\_-\\_BHBMEG_20190507142627.json\n‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 010\\_.\\_RESEARCH\\_-\\_BHBMEG_20190507142627.nii.gz\n‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 011\\_.\\_RESEARCH\\_-\\_BHBMEG_20190507142627.json\n‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 011\\_.\\_RESEARCH\\_-\\_BHBMEG_20190507142627.nii.gz\n‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 012\\_.\\_RESEARCH\\_-\\_BHBMEG_20190507142627.json\n‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 012\\_.\\_RESEARCH\\_-\\_BHBMEG_20190507142627.nii.gz\n‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 013\\_.\\_RESEARCH\\_-\\_BHBMEG_20190507142627.json\n‚îÇ¬†¬† ‚îÇ¬†¬† ‚îî‚îÄ‚îÄ 013\\_.\\_RESEARCH\\_-\\_BHBMEG_20190507142627.nii.gz\n‚îÇ¬†¬† ‚îî‚îÄ‚îÄ log\n‚îÇ¬†¬† ‚îî‚îÄ‚îÄ helper_20240109-144412.log\n‚îú‚îÄ‚îÄ sub-BHBMEG004\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ anat\n‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ sub-BHBMEG004_ses-brainmap_T1W.json\n‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ sub-BHBMEG004_ses-brainmap_T1W.nii.gz\n‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ sub-BHBMEG004_ses-eegfmri_T1W.json\n‚îÇ¬†¬† ‚îÇ¬†¬† ‚îî‚îÄ‚îÄ sub-BHBMEG004_ses-eegfmri_T1W.nii.gz\n‚îÇ¬†¬† ‚îî‚îÄ‚îÄ func\\\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ sub-BHBMEG004_ses-eegfmri_task-handstim_bold.json\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ sub-BHBMEG004_ses-eegfmri_task-handstim_bold.nii.gz\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ sub-BHBMEG004_ses-eegfmri_task-rest_run-01_bold.json\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ sub-BHBMEG004_ses-eegfmri_task-rest_run-01_bold.nii.gz\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ sub-BHBMEG004_ses-eegfmri_task-rest_run-02_bold.json\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ sub-BHBMEG004_ses-eegfmri_task-rest_run-02_bold.nii.gz\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ sub-BHBMEG004_ses-eegfmri_task-rest_run-03_bold.json\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ sub-BHBMEG004_ses-eegfmri_task-rest_run-03_bold.nii.gz\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ sub-BHBMEG004_ses-eegfmri_task-rest_run-04_bold.json\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ sub-BHBMEG004_ses-eegfmri_task-rest_run-04_bold.nii.gz\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ sub-BHBMEG004_ses-eegfmri_task-rest_run-05_bold.json\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ sub-BHBMEG004_ses-eegfmri_task-rest_run-05_bold.nii.gz\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ sub-BHBMEG004_ses-eegfmri_task-rest_run-06_bold.json\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ sub-BHBMEG004_ses-eegfmri_task-rest_run-06_bold.nii.gz\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ sub-BHBMEG004_ses-eegfmri_task-rest_run-07_bold.json\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ sub-BHBMEG004_ses-eegfmri_task-rest_run-07_bold.nii.gz\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ sub-BHBMEG004_ses-eegfmri_task-rest_run-08_bold.json\n‚îÇ¬†¬† ‚îî‚îÄ‚îÄ sub-BHBMEG004_ses-eegfmri_task-rest_run-08_bold.nii.gz\n‚îî‚îÄ‚îÄ tmp_dcm2bids\n¬†¬† ‚îú‚îÄ‚îÄ log\n¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ scaffold_20240109-142635.log\n¬†¬† ‚îÇ¬†¬† ‚îî‚îÄ‚îÄ sub-BHBMEG004_20240109-180638.log\n¬†¬† ‚îî‚îÄ‚îÄ sub-BHBMEG004\nDeactivate the dcm2bids environment in Terminal.\nconda deactivate\n\n\n\nFor the T1 scan(s) for both the BHBEP and BHBMEG sessions, get the freesurfer surfaces and inflated spheres using recon-all. We will need these to align the EEG data with the MRI data. Include the T1 from the brain mapping session if there is one.\nmkdir BIDS/BHBMEG&lt;subject_id&gt;/derivatives/freesurfer\n\nrecon-all -subject sub-BHBMEG\\&lt;subject_id\\&gt; -I \\&lt;path to anat\nfolder\\&gt;/sub-BHBMEG\\&lt;subject_id\\&gt;\\_ses-eegfmri_T1W.nii.gz -i\nsub-BHBMEG\\&lt;subject_id\\&gt;\\_ses-brainmap_T1W.nii.gz -sd \\&lt;path to BIDS\nfolder\\&gt;/BHBMEG\\&lt;subject_id\\&gt;/derivatives/freesurfer -all\nBe sure to record the¬†freesurfer¬†subject as¬†sub-BHBMEG&lt;id_number&gt; in the derivatives/freesurfer folder. Use the instructions at ¬†https://surfer.nmr.mgh.harvard.edu/fswiki/recon-all¬†if you need help setting this up.\n\n\n\nInstall MNE if you haven‚Äôt done so already (https://mne.tools/stable/install/manual_install.html#manual-install).\nconda install --channel=conda-forge --name=base conda-libmamba-solver\nconda create --solver=libmamba --override-channels\n--channel=conda-forge --name=mne mne\nIf you don't already have them, also install¬†docker (https://docs.docker.com/desktop/install/mac-install/) and add the¬†fmriprep¬†command to your anaconda installation (https://www.anaconda.com/download) using:\nconda activate mne\npip install fmriprep-docker\nconda deactivate\nThen at the command line enter:\nconda activate mne\n\ncd &lt;BIDS_root&gt;code\nzsh fmriprep_command.sh\nconda deactivate\nThis will preprocess the fMRI data in your¬†BHBMEG&lt;subject_id&gt;¬†folder. Be sure to check the quality assurance document that gets outputted in the¬†derivatives/fmriprep¬†folder. If necessary, adjust¬†fmriprep_command.sh¬†and rerun.",
    "crumbs": [
      "Home",
      "MRI Methods",
      "EEG-fMRI",
      "EEG-fMRI Data Cleaning & Forward Solution"
    ]
  },
  {
    "objectID": "mrimethods/eeg-fmri/gradient-removal.html#eeg-cleaning",
    "href": "mrimethods/eeg-fmri/gradient-removal.html#eeg-cleaning",
    "title": "EEG-fMRI Data Cleaning & Forward Solution",
    "section": "",
    "text": "Make a directory called¬†eeg¬†in the sourcedata folder. Copy all the EEG data files from NetStation in¬†.mff¬†format into the¬†sourcedata/eeg¬†folder.\nOpen Spyder from the command line in Terminal.\nSpyder\nChange Spyder's Python interpreter to that in the MNE Environment. Click on the wrench in the toolbar. When the dialogue box opens, select Python Interpreter in the left column. Select the mne python interpreter in the list of the python interpreters on the right. It should have your anaconda3 install in the python interpreter name. Mine is:\n![[Pasted image 20240213120910.png]]\nClick OK.\nOpen the¬†convert_mff_to_bids.py¬†script. It is in the¬†code¬†directory in your subject‚Äôs BIDS directory.\nUpdate¬†convert_mff_to_bids.py¬†to list the EEG files from NetStation if you haven't already done so. Enter the filenames for each file. There will be somewhere between 1 and the number of MR resting state + the hand stim task runs of EEG data.\nIf the number of EEG runs is equal to the number of MR runs, use the first and last data points as the EEG run start and end (default). If the number of EEG runs is less than the number of MR runs, use the notes taken during acquisition to determine which MR runs are included in each EEG run. Once the distribution of MR runs in each EEG file is determined, open the data in your favourite viewer and mark timepoints between runs (this is the ‚Äúquiet‚Äù periods between MR gradient artifacts. Pick a point about midway between the 2 MR runs and note the value in milliseconds. This will be the end point of your EEG run. Add one millisecond and this will be the beginning of the next MR run.\nOnce you have determined the break point values, run the script.\n\n\nThe first thing to be created is the¬†bem¬†folder in the¬†derivatives/freesurfer/sub-BHBMEG&lt;subject_id&gt;¬†folder. The make_bem flag in convert_mff_to_bids.py needs to be set to True.\nmake_bem = True\nThe¬†freesurfer¬†recon-all run above needs to have completed before doing this. This will create the head and scalp surfaces from your¬†freesurfer¬†output.\n\n\n\nIf you don't already have a .trans¬†file in your¬†derivatives/mne¬†folder, we will now create one. When you run convert_mff_to_bids.py, the graphical user interface for¬†PyVista will open. Be patient with¬†PyVista, it takes a very long time to load. You will see the outer skin surface with 3 marks. This is the program's best guess at where the nasion and preauricular points are on the scalp surface.\n\nIf the points don't align with the marks from the EEG net, realign the points to correspond to where the EEG net was placed.\nOn the left side, if the Lock fiducials checkbox is checked, uncheck it. Underneath you have LPA. This is the left preauricular point. Click on the radio button beside LPA.\n\nMove the red fiducial marker to the circleish place in front of the ear corresponding to the placement of the preauricular point from the EEG net.\n\nThis gives the relationship between the EEG net placement and the underlying MR anatomy.\nNow click on the radio button beside Nasion. Move the green fiducial marker to where the EEG net is sitting on the face.\n\nRepeat for the right preauricular point (RPA).\n\n\n\n\nFill in the MR runs contained in each EEG run. The script will ask you for this information. Remember to include the opening and closing square brackets (e.g., [3, 4, 5, ‚Ä¶]) for the list of MR runs contained in the EEG run. The MR run will not have a value of less than 3 because of the calibration scans preceding the scan.\nEnter the start and end points of each MR run in the EEG data when asked to do so if more than one MR run is in an EEG run (i.e., n_mr_runs &gt; n_eeg_runs) in the¬†convert_mff_to_bids.py¬†script.\nThis script will save a¬†EEGLAB¬†.set¬†file in the derivatives/mne¬†directory for the eeg data corresponding to each MR run labeled with the run numbers in the¬†BIDS directory.\n\n\n\nDownload¬†EEGLAB¬†from¬†https://sccn.ucsd.edu/eeglab/download.php. Follow the install instructions. Add the¬†EEGLAB¬†path to your¬†Matlab¬†path.\nIn the Matlab command window, type\neeglab\nThis will open the following dialogue box:\n\nIf you haven't already done so, add the fMRIb MRI Tools. In the main EEGLAB window, go to¬†File &gt; Manage EEGLAB extensions. This will open another dialogue box:\n\nIn the search bar, type in¬†MRI.\n\nSelect the extension labelled¬†fMRIb¬†(download the latest stable version).\n\nClick¬†Install/Update.\nClose the main EEGLAB window.",
    "crumbs": [
      "Home",
      "MRI Methods",
      "EEG-fMRI",
      "EEG-fMRI Data Cleaning & Forward Solution"
    ]
  },
  {
    "objectID": "mrimethods/eeg-fmri/gradient-removal.html#remove-mr-gradient-artifact-using-fimrib-eeglab-plugin",
    "href": "mrimethods/eeg-fmri/gradient-removal.html#remove-mr-gradient-artifact-using-fimrib-eeglab-plugin",
    "title": "EEG-fMRI Data Cleaning & Forward Solution",
    "section": "",
    "text": "Change the¬†Matlab¬†directory to the root of your BIDS folder structure for your subject. In Matlab 2022a, this is:\ncd &lt;path to BIDS root&gt;\nNote that you must use Matlab 2018b or above with the signal processing and the stats toolboxes. If you don‚Äôt have the toolboxes, contact BCCHR IT.\nYou want to open the .set file for the EEG-MRI run stored in your¬†derivatives/mne/sub-&lt;subject_id&gt;¬†folder.\nOpen the main¬†EEGLAB window.\neeglab\nClick¬†File &gt; Load existing dataset. Navigate to the¬†derivatives/mne/sub-&lt;subject_id&gt;¬†folder. Select the .set file for the EEG-fMRI run you want to process.\n\nNow we need to get the TRs. They have been saved as an extra channel. They should be stored in channel 258, but we want to check first. Go to¬†Plot &gt; Channel data (scroll).\n\nHowever, the display is too busy. Go to¬†Settings &gt; Number of channels¬†to display. In the pop-up dialogue box, put a number between 10 and 25, depending upon the size of your monitor and what you feel more comfortable with. Click¬†Ok. Scroll down using the bar on the left. Check that TR is listed as channel 258.\n\nThe noise in the data is the gradient artifact.\nNow that we have verified that the TRs are stored in channel 258 click¬†CANCEL.\nNow we need the TRs as events and not as a channel. Go to¬†File &gt; Import event data &gt; From data channel.\n\nEnter 258 for¬†Event channel(s). Be sure to unclick¬†Delete event channel(s)¬†and¬†Delete old events¬†if any. Your display should look like the above dialogue box. Click¬†Ok.\nIn the original dialogue box, go to¬†Tools &gt; FMRIB Tools &gt; FASTR: Remove MRI gradient artifacts. Again, this will open another dialogue box.\n\nThe TRs come one for every volume. Change Artifact timing event to Volume/Section. Make sure that the Artifact timing event reads either TR or the channel that you entered for the TR signal from the previous step (usually chan258, but check to be sure). Check the box beside Adaptive Noise Cancellation.\n\nPress Ok.\nRepeat for all other functional MR runs.\n\n\nThis algorithm uses Cameron Rodriguez's (2016) method to derive the cardiac signal from selected channels in the EEG signal. Please see¬†Rodriguez (2016)¬†for more details.\nIn¬†Matlab¬†open the¬†RemoveBallistocardiogram.mlx¬†file from the¬†code¬†directory in your subject's root BIDS directory. Note that you need to be using¬†Matlab 2022a or above¬†and have the¬†signal processing toolbox¬†installed. If you don't have these, contact BCCHR/UBC IT to find out how to get these for your account.\nOnce¬†RemoveBallistocardiogram.mlx¬†is open, change the data in boxes 1 through 3. In the first box, change¬†e¬†to the number of MR runs of resting state data that you have (e.g., e = 7 MR runs). Next, change the names of the output files in BIDS format to fit your data. You should only have to change the¬†sub-BHBMEG&lt;subject_id&gt;**¬†part and change the number of successful MR runs. This will put¬†.txt¬†files with the SPPeaks of the cardiac signal.\n\nNext, we need to add the path to our gradient removed eeg data in the ./derivatives/mne folder of the root BIDS directory.\n\nOnce you have your directory path set, fill in the names of each of your gradient cleaned EEG runs.\n\nNow in¬†Matlab\\'s LIVE EDITOR¬†window, press the¬†run¬†button (green right pointing arrowhead). The script will loop through your EEG runs for each MR run and output a .txt file for each run. These are the SPPeaks from the cardiac symbol.\n\n\n\n\nNow that you have the files with the SP Peaks, you are ready to remove the ballistocardiogram from your EEG signal. In¬†Matlab, open¬†EEGLAB:\neeglab\nIn the EEGLAB main window, open the first of your gradient cleaned EEG .set files (i.e.,¬†sub-BHBMEG&lt;subject_id&gt;_ses-eegfmri_task-rest_run-&lt;run number&gt;_desc-gr_eeg.set) using¬†File \\&gt; Load existing dataset. Once opened, we need to import the .txt file with the events corresponding to the SP Peaks in that particular run. To do that, we go to File &gt; Import event info &gt; From MATLAB array or ASCII file. This will open the following dialogue box:\n\nSelect Browse and select the¬†BHBMEG&lt;subject_id&gt;_ses-eegfmri_task-rest_run-&lt;run number&gt;_desc-gr-sppeak_eeg.txt¬†file corresponding to the EEG run you loaded previously. Add the words latency type to the Input field (column) names box, change the Number of file header lines to 1, the Time unit (sec) to NaN and uncheck the **Auto adjust new events sampling rate. Your dialogue box should look like the following:\n\nPress Ok.\nCheck that the file loaded in the main EEGLAB window. The number of events should increase by at least approximately six hundred to fifteen hundred (give or take a bit to adjust for changes and individual differences in heart rate).\n\nNow we need to go to Tools &gt; fMRIb Tools &gt; Remove pulse artifacts. This will open the following dialogue box:\n\nMake sure QRS/Heartbeat Event is sppeak. Select Optimal Basis Set. Leave the default value of 3 in the Number of PCs to use. Press Ok.\nYou will see the progress in the Matlab Console window.\n\nOnce completed, be sure to save the new file as¬†BHBMEG&lt;subject_id&gt;_ses-eegfmri_task-rest_run-&lt;run number&gt;_desc-gr-sppeak-qrs_eeg.set. Overwrite the gradient cleaned version in the main EEGLAB window.\n\nCheck the data by opening the file in the EEGLAB viewer. Go to Plot &gt; Channel data (scroll. In the plot window, select Display &gt; Remove DC offset and Settings &gt; Number of channels to display. Set the number in the new dialogue box to somewhere between 10 and 20 channels depending upon your preference.\n\nExport the data in¬†.edf¬†format so that the epileptologist can view the file in¬†Natus¬†(the proprietary system used in the EEG department) or NetStation. In the main EEGLAB¬†window, select File \\&gt; Export \\&gt; Data¬†to EDF/BDF/GDF file. If you are asked to install the Biosig extension, press¬†Yes. Save the file as¬†sub-BHBMEG\\&lt;subject_id\\&gt;\\_ses-eegfmri_task-rest_run-\\&lt;run number\\&gt;\\_desc-gr-sppeak-qrs_eeg.edf. Make sure to use the .edf file extension. This will open a dialogue box:\n\nHighlight EDF and press Ok. This will write the EDF file to disk.\nRepeat the Remove Ballistocardiogram using FIMRIB EEGLAB Plugin steps for all other MR/EEG gradient cleaned files (one corresponding to each MR run).\n\n\n\nOnce you are finished cleaning and checking the EEG data, notify the epileptologist who made the referral for spike reading in the EEG file. Ask if they would prefer to read the spikes in¬†Natus¬†or¬†Netstation and prepare the software accordingly. If using Natus, you will need to make arrangements with the EEG department to bring the files over and have them installed on their¬†Natus¬†system. If loading in Natus, be sure to bring the patient‚Äôs name and date of birth along with the anonymized¬†.edf¬†files as the records will become part of the EEG department‚Äôs records for that patient/subject. If you don‚Äôt want the results to become part of the patient‚Äôs medical record, make sure the epileptologist reads the data in NetStation in the Brain Mapping Lab.\nOnce the epileptologist has read the spikes in each run, export the events from either¬†Netstation¬†or¬†Natus¬†for each run to a¬†.txt¬†(ASCII file). It is these events that will be used to\n\nrun an¬†event-related design¬†for your fMRI runs in¬†FSL FEAT, and\ncreate epochs and run a¬†beamformer¬†in¬†MNE.\n\nReferences\nRodriguez, C. (2016).¬†Improvements to Simultaneous Electroencepalography-Functional Magnetic Resonance Imaging and Electroencepalographic Source Localization. Dissertation.¬†https://escholarship.org/uc/item/3gg3z2q6",
    "crumbs": [
      "Home",
      "MRI Methods",
      "EEG-fMRI",
      "EEG-fMRI Data Cleaning & Forward Solution"
    ]
  },
  {
    "objectID": "orientation/instantmessaging.html",
    "href": "orientation/instantmessaging.html",
    "title": "Mattermost: Instant Messaging / Stay in Touch",
    "section": "",
    "text": "Mattermost is an open-source alternative to Slack and Microsoft Teams. Similar to those programs, it is a tool for instant messaging and collaboration.  If you have MRI questions or want to connect with other BCCH MRI Research Facility users, you can use Mattermost to connect with us.",
    "crumbs": [
      "Home",
      "Orientation",
      "Mattermost: Instant Messaging / Stay in Touch"
    ]
  },
  {
    "objectID": "orientation/instantmessaging.html#bcchr-it-instructions",
    "href": "orientation/instantmessaging.html#bcchr-it-instructions",
    "title": "Mattermost: Instant Messaging / Stay in Touch",
    "section": "BCCHR IT Instructions",
    "text": "BCCHR IT Instructions\nIf you are on the BCCHR VPN, you can follow instructions from the BCCHR Hub here:\nhttps://hub.bcchr.ca/display/it/Mattermost\nOtherwise, you can follow these directions:",
    "crumbs": [
      "Home",
      "Orientation",
      "Mattermost: Instant Messaging / Stay in Touch"
    ]
  },
  {
    "objectID": "orientation/instantmessaging.html#setup",
    "href": "orientation/instantmessaging.html#setup",
    "title": "Mattermost: Instant Messaging / Stay in Touch",
    "section": "Setup",
    "text": "Setup\n[NOTE: You will need a BCCHR username and password to gain access.]\n\nFirst thing you will want to do is get invited to our ‚Äòteam‚Äô:\nClick here to be invited\nIf that link does not work, you can submit a request to IT via support.bcchr.ca\nYou will be asked ‚ÄúWhere would you like to view this?‚Äù For now, click ‚ÄúView in Browser‚Äù\nYou will be asked to login with your BCCHR username and password: \nAfter you are given access, refresh the login (i.e.¬†log out and log back in to https://im.bcchr.ca)",
    "crumbs": [
      "Home",
      "Orientation",
      "Mattermost: Instant Messaging / Stay in Touch"
    ]
  },
  {
    "objectID": "orientation/instantmessaging.html#installation",
    "href": "orientation/instantmessaging.html#installation",
    "title": "Mattermost: Instant Messaging / Stay in Touch",
    "section": "Installation",
    "text": "Installation\n\nBrowser\nAs described above, you can check out Mattermost on your browser first before you decide to install the app on your computer or phone:\nhttps://im.bcchr.ca/\n\n\nDesktop\nFor your computer, you will want to install Mattermost Desktop. Click here to choose your operating system and use their installation guide.\nFor server display name, use: BCCH Research MRI\nFor server URL, use: https://im.bcchr.ca/\nLogin with your BCCHR username and password\n\n\nMobile\nMattermost can also be installed on your phone. Click here to choose your phone operating system.\nFor server display name, use: BCCH Research MRI\nFor server URL, use: https://im.bcchr.ca/\nLogin with your BCCHR username and password",
    "crumbs": [
      "Home",
      "Orientation",
      "Mattermost: Instant Messaging / Stay in Touch"
    ]
  },
  {
    "objectID": "orientation/instantmessaging.html#next-steps",
    "href": "orientation/instantmessaging.html#next-steps",
    "title": "Mattermost: Instant Messaging / Stay in Touch",
    "section": "Next Steps",
    "text": "Next Steps\n\nLearn more\nIf you want to learn more about Mattermost and its features, visit https://docs.mattermost.com/guides/user.html\n\n\nAdd A Photo of Yourself\nIt can be very helpful to others to include a photo or yourself.\n\nGo to Account Settings (Top right on Desktop app, and bottom right on Mobile app)\nClick on Your Profile\nEdit your Profile Picture\n\n\n\nNotifications",
    "crumbs": [
      "Home",
      "Orientation",
      "Mattermost: Instant Messaging / Stay in Touch"
    ]
  },
  {
    "objectID": "mrisoftware/index.html",
    "href": "mrisoftware/index.html",
    "title": "MRI Software",
    "section": "",
    "text": "3D Slicer\n\n\n\n\n\n\nsoftware\n\n\nvisualization\n\n\nmedical imaging\n\n\n\n3D Slicer is an open-source software platform used for visualization, segmentation, and modeling of medical imaging data in 3D.\n\n\n\n\n\nFeb 28, 2025\n\n\nAlexander Weber\n\n\n\n\n\n\nNo matching items\n\n Back to top",
    "crumbs": [
      "Home",
      "MRI Software"
    ]
  }
]